{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess snowline altitude uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions\n",
    "code_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/glacier-snow-cover-analysis/'\n",
    "sys.path.append(os.path.join(code_path, 'functions'))\n",
    "import utils as f\n",
    "\n",
    "# Define path to snow cover data and site names\n",
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping'\n",
    "rgi_ids = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(scm_path, 'study-sites', 'RGI*')))]\n",
    "rgi_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate SLA bounds (uncertainty) for all sites and classified images\n",
    "\n",
    "The original SLA was calculated by sampling the $1-AAR$ percentile of the DEM. For example, if the AAR is 0.8, the SLA is calculated as the 20th percentile of elevations over the glacier area. \n",
    "\n",
    "$P_{SLA} = 1-AAR$\n",
    "\n",
    "$SLA = P_{SLA}(DEM)$\n",
    "\n",
    "To estimate upper and lower bounds for SLA, identify \"misclassified\" pixels above and below the SLA, and use those to adjust the SLA percentile. \n",
    "\n",
    "For the upper bound, calculate the area of snow-free pixels above the SLA, convert that to a percentile relative to the total area, and add that to the original SLA percentile. Sample the $P_{upper}$ of the DEM.  \n",
    "\n",
    "$P_{upper} = \\frac{A_{snow free, above SLA}}{A_{glacier}} + P_{SLA}$\n",
    "\n",
    "$SLA_{upper} = P_{upper}(DEM)$\n",
    "\n",
    "For the lower bound, calculate the area of snow-covered pixels below the SLA, convert that to a percentile relative to the total area, and subtract that from the original SLA percentile. Sample the $P_{lower}$ of the DEM. \n",
    "\n",
    "$P_{lower} = -\\frac{A_{snow covered, below SLA}}{A_{glacier}} + P_{SLA}$\n",
    "\n",
    "$SLA_{lower} = P_{lower}(DEM)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file name\n",
    "sla_bounds_fn = os.path.join(scm_path, 'analysis', 'SLA_uncertainty_analysis.csv')\n",
    "if not os.path.exists(sla_bounds_fn):\n",
    "    # Initialize results DataFrame\n",
    "    sla_bounds_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over sites\n",
    "    for rgi_id in tqdm(rgi_ids[0:1]):\n",
    "        # Load snow cover stats\n",
    "        scs_fn = os.path.join(scm_path, 'study-sites', rgi_id, f\"{rgi_id}_snow_cover_stats.csv\")\n",
    "        # skip if snow cover stats or classified images do not exist\n",
    "        if not os.path.exists(scs_fn):\n",
    "            continue\n",
    "        if not os.path.exists(os.path.join(scm_path, 'study-sites', rgi_id, 'classified')):\n",
    "            continue\n",
    "        scs = pd.read_csv(scs_fn)\n",
    "        # remove rows where AAR = 1\n",
    "        scs = scs.loc[scs['AAR'] < 1].reset_index(drop=True)\n",
    "        \n",
    "        # Load DEM\n",
    "        dem_fn = glob.glob(os.path.join(scm_path, 'study-sites', rgi_id, 'DEMs', '*.tif'))[0]\n",
    "        dem = rxr.open_rasterio(dem_fn).isel(band=0)\n",
    "        dem = xr.where((dem < -1e3) | (dem > 1e4), np.nan, dem)\n",
    "        dem = dem.rio.write_crs(\"EPSG:4326\")\n",
    "        \n",
    "        # Load AOI\n",
    "        aoi_fn = os.path.join(scm_path, 'study-sites', rgi_id, 'AOIs', f\"{rgi_id}_outline.shp\")\n",
    "        aoi = gpd.read_file(aoi_fn)\n",
    "        \n",
    "        # Clip DEM to AOI\n",
    "        dem = dem.rio.clip(aoi.geometry)\n",
    "    \n",
    "        # Iterate over snow cover observations\n",
    "        sla_originals = np.zeros(len(scs))\n",
    "        sla_lower_bounds = np.zeros(len(scs))\n",
    "        sla_upper_bounds = np.zeros(len(scs))\n",
    "        dts = [''] * len(scs)\n",
    "        sources = [''] * len(scs)\n",
    "        for i in range(len(scs)):\n",
    "            sc = scs.iloc[i]\n",
    "            # Load classified image file\n",
    "            dts[i] = sc['datetime']\n",
    "            sources[i] = sc['source']\n",
    "            classified_fn = glob.glob(os.path.join(scm_path, 'study-sites', rgi_id, 'classified', \n",
    "                                                   f\"{dts[i].replace('-', '').replace(':','')}_{rgi_id}_{sources[i]}_classified.nc\"))[0]\n",
    "            classified = rxr.open_rasterio(classified_fn).squeeze()\n",
    "            classified = xr.where(classified==-9999, np.nan, classified)\n",
    "            classified = classified.rio.write_crs(\"EPSG:4326\")\n",
    "            \n",
    "            # Create binary snow image\n",
    "            snow_binary = xr.where((classified==1) | (classified==2), 1, 0)\n",
    "            snow_binary = xr.where(np.isnan(classified), np.nan, snow_binary) # re-insert no data values\n",
    "            \n",
    "            # Regrid DEM to classified image grid\n",
    "            dem_adj = dem.rio.reproject_match(classified)\n",
    "            dem_adj = xr.where(dem_adj > 1e4, np.nan, dem_adj)\n",
    "            dem_adj = dem_adj.rio.write_crs(\"EPSG:4326\")\n",
    "            \n",
    "            # Determine spatial resolution based on source\n",
    "            if sources[i]=='Landsat':\n",
    "                dx = 30\n",
    "            elif 'Sentinel-2' in sources[i]:\n",
    "                dx = 10\n",
    "            \n",
    "            # Calculate lower and upper bounds of snowline altitude\n",
    "            sla_originals[i], sla_lower_bounds[i], sla_upper_bounds[i] = f.calculate_sla_bounds(sc, dem_adj, snow_binary, dx=dx, verbose=False)\n",
    "            \n",
    "        # Save in DataFrame\n",
    "        df = pd.DataFrame({'RGIId': [rgi_id] * len(scs),\n",
    "                           'datetime': dts,\n",
    "                           'source': sources,\n",
    "                           'SLA_m': sla_originals,\n",
    "                           'SLA_lower_bound_m': sla_lower_bounds,\n",
    "                           'SLA_upper_bound_m': sla_upper_bounds})\n",
    "        \n",
    "        # Concatenate to results DataFrame\n",
    "        sla_bounds_df = pd.concat([sla_bounds_df, df], axis=0)\n",
    "    \n",
    "    # Save results to file\n",
    "    sla_bounds_df.reset_index(drop=True, inplace=True)\n",
    "    sla_bounds_df.to_csv(sla_bounds_fn, index=False)\n",
    "    print('SLA bounds saved to file:', sla_bounds_fn)\n",
    "    \n",
    "else:\n",
    "    sla_bounds_df = pd.read_csv(sla_bounds_fn)\n",
    "\n",
    "# Add column for total range and describe stats\n",
    "sla_bounds_df['SLA_bounds_range_m'] = np.abs(sla_bounds_df['SLA_upper_bound_m'] - sla_bounds_df['SLA_lower_bound_m'])\n",
    "plt.boxplot(sla_bounds_df['SLA_bounds_range_m'], showfliers=False)\n",
    "plt.show()\n",
    "\n",
    "sla_bounds_df['SLA_bounds_range_m'].describe()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glacier-snow-cover-mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
