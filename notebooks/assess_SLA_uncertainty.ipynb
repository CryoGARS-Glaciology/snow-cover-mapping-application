{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess snowline altitude uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to snow cover data and site names\n",
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping'\n",
    "rgi_ids = [os.path.basename(x) for x in sorted(glob.glob(os.path.join(scm_path, 'study-sites', 'RGI*')))]\n",
    "rgi_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function for calculating SLA lower and upper bounds\n",
    "\n",
    "The original SLA was calculated by sampling the $1-AAR$ percentile of the DEM. For example, if the AAR is 0.8, the SLA is calculated as the 20th percentile of elevations over the glacier area. \n",
    "\n",
    "$P_{SLA} = 1-AAR$\n",
    "\n",
    "$SLA = P_{SLA}(DEM)$\n",
    "\n",
    "To estimate upper and lower bounds for SLA, identify \"misclassified\" pixels above and below the SLA, and use those to adjust the SLA percentile. \n",
    "\n",
    "For the upper bound, calculate the area of snow-free pixels above the SLA, convert that to a percentile relative to the total area, and add that to the original SLA percentile. Sample the $P_{upper}$ of the DEM.  \n",
    "\n",
    "$P_{upper} = \\frac{A_{snow free, above SLA}}{A_{glacier}} + P_{SLA}$\n",
    "\n",
    "$SLA_{upper} = P_{upper}(DEM)$\n",
    "\n",
    "For the lower bound, calculate the area of snow-covered pixels below the SLA, convert that to a percentile relative to the total area, and subtract that from the original SLA percentile. Sample the $P_{lower}$ of the DEM. \n",
    "\n",
    "$P_{lower} = -\\frac{A_{snow covered, below SLA}}{A_{glacier}} + P_{SLA}$\n",
    "\n",
    "$SLA_{lower} = P_{lower}(DEM)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sla_bounds(stats_df, dem, snow_cover_mask, dx, verbose=False):\n",
    "    # Get original snow cover stats and SLA percentile from DataFrame\n",
    "    aar = stats_df['AAR']\n",
    "    sla = stats_df['ELA_from_AAR_m']\n",
    "    sla_percentile = 1 - aar\n",
    "\n",
    "    # Calculate glacier area\n",
    "    npx = len(np.argwhere(~np.isnan(dem.data.ravel())).ravel())\n",
    "    total_area = npx * dx**2\n",
    "        \n",
    "    # Calculate areas of misclassified pixels\n",
    "    snow_free_above_sla = xr.where((dem > sla) & (snow_cover_mask == 0), 1, 0)\n",
    "    snow_free_above_sla_area = len(np.argwhere(snow_free_above_sla.data.ravel()==1).ravel()) * dx**2\n",
    "    snow_covered_below_sla = xr.where((dem < sla) & (snow_cover_mask == 1), 1, 0)\n",
    "    snow_covered_below_sla_area = len(np.argwhere(snow_covered_below_sla.data.ravel()==1).ravel()) * dx**2\n",
    "\n",
    "    # Convert areas to percentiles\n",
    "    delta_up = snow_free_above_sla_area / total_area\n",
    "    delta_down = snow_covered_below_sla_area / total_area\n",
    "        \n",
    "    # Adjust SLA percentiles\n",
    "    upper_sla_percentile = sla_percentile + delta_up\n",
    "    lower_sla_percentile = sla_percentile - delta_down\n",
    "    # Make sure percentiles are within [0,1]\n",
    "    upper_sla_percentile, lower_sla_percentile = np.clip([upper_sla_percentile, lower_sla_percentile], 0, 1)\n",
    "\n",
    "    # Calculate SLA upper and lower bounds\n",
    "    sla_upper_bound = np.nanpercentile(dem.data.ravel(), upper_sla_percentile * 100)\n",
    "    sla_lower_bound = np.nanpercentile(dem.data.ravel(), lower_sla_percentile * 100)\n",
    "\n",
    "    # Print results if requested\n",
    "    if verbose:\n",
    "        print(f\"Total area = {np.round(total_area / 1e6,2)} km^2\")\n",
    "        print(f\"Area of snow-free pixels above SLA = {np.round(snow_free_above_sla_area / 1e6, 2)} km^2\")\n",
    "        print(f\"Area of snow-covered pixels below SLA = {np.round(snow_covered_below_sla_area / 1e6, 2)} km^2\")\n",
    "        print(f\"AAR = {np.round(aar, 3)}\")\n",
    "        print(f\"SLA percentile = {np.round(sla_percentile, 3)}\")\n",
    "        print(f\"SLA upper-bound percentile = {np.round(upper_sla_percentile, 3)}\")\n",
    "        print(f\"SLA lower-bound percentile = {np.round(lower_sla_percentile, 3)}\")\n",
    "        print(f\"SLA = {np.round(sla, 2)} m\")\n",
    "        print(f\"SLA upper-bound = {np.round(sla_upper_bound, 2)} m\")\n",
    "        print(f\"SLA lower-bound = {np.round(sla_lower_bound, 2)} m\")\n",
    "        \n",
    "    return sla, sla_upper_bound, sla_lower_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate SLA bounds (uncertainty) for all sites and classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file name\n",
    "sla_bounds_fn = os.path.join(scm_path, 'analysis', 'SLA_uncertainty_analysis.csv')\n",
    "if not os.path.exists(sla_bounds_fn):\n",
    "    # Initialize results DataFrame\n",
    "    sla_bounds_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over sites\n",
    "    for rgi_id in tqdm(rgi_ids[0:1]):\n",
    "        # Load snow cover stats\n",
    "        scs_fn = os.path.join(scm_path, 'study-sites', rgi_id, f\"{rgi_id}_snow_cover_stats.csv\")\n",
    "        # skip if snow cover stats or classified images do not exist\n",
    "        if not os.path.exists(scs_fn):\n",
    "            continue\n",
    "        if not os.path.exists(os.path.join(scm_path, 'study-sites', rgi_id, 'classified')):\n",
    "            continue\n",
    "        scs = pd.read_csv(scs_fn)\n",
    "        # remove rows where AAR = 1\n",
    "        scs = scs.loc[scs['AAR'] < 1].reset_index(drop=True)\n",
    "        \n",
    "        # Load DEM\n",
    "        dem_fn = glob.glob(os.path.join(scm_path, 'study-sites', rgi_id, 'DEMs', '*.tif'))[0]\n",
    "        dem = rxr.open_rasterio(dem_fn).isel(band=0)\n",
    "        dem = xr.where((dem < -1e3) | (dem > 1e4), np.nan, dem)\n",
    "        dem = dem.rio.write_crs(\"EPSG:4326\")\n",
    "        \n",
    "        # Load AOI\n",
    "        aoi_fn = os.path.join(scm_path, 'study-sites', rgi_id, 'AOIs', f\"{rgi_id}_outline.shp\")\n",
    "        aoi = gpd.read_file(aoi_fn)\n",
    "        \n",
    "        # Clip DEM to AOI\n",
    "        dem = dem.rio.clip(aoi.geometry)\n",
    "    \n",
    "        # Iterate over snow cover observations\n",
    "        sla_originals = np.zeros(len(scs))\n",
    "        sla_lower_bounds = np.zeros(len(scs))\n",
    "        sla_upper_bounds = np.zeros(len(scs))\n",
    "        dts = [''] * len(scs)\n",
    "        sources = [''] * len(scs)\n",
    "        for i in range(len(scs)):\n",
    "            sc = scs.iloc[i]\n",
    "            # Load classified image file\n",
    "            dts[i] = sc['datetime']\n",
    "            sources[i] = sc['source']\n",
    "            classified_fn = glob.glob(os.path.join(scm_path, 'study-sites', rgi_id, 'classified', \n",
    "                                                   f\"{dts[i].replace('-', '').replace(':','')}_{rgi_id}_{sources[i]}_classified.nc\"))[0]\n",
    "            classified = rxr.open_rasterio(classified_fn).squeeze()\n",
    "            classified = xr.where(classified==-9999, np.nan, classified)\n",
    "            classified = classified.rio.write_crs(\"EPSG:4326\")\n",
    "            \n",
    "            # Create binary snow image\n",
    "            snow_binary = xr.where((classified==1) | (classified==2), 1, 0)\n",
    "            snow_binary = xr.where(np.isnan(classified), np.nan, snow_binary) # re-insert no data values\n",
    "            \n",
    "            # Regrid DEM to classified image grid\n",
    "            dem_adj = dem.rio.reproject_match(classified)\n",
    "            dem_adj = xr.where(dem_adj > 1e4, np.nan, dem_adj)\n",
    "            dem_adj = dem_adj.rio.write_crs(\"EPSG:4326\")\n",
    "            \n",
    "            # Determine spatial resolution based on source\n",
    "            if sources[i]=='Landsat':\n",
    "                dx = 30\n",
    "            elif 'Sentinel-2' in sources[i]:\n",
    "                dx = 10\n",
    "            \n",
    "            # Calculate lower and upper bounds of snowline altitude\n",
    "            sla_originals[i], sla_lower_bounds[i], sla_upper_bounds[i] = calculate_sla_bounds(sc, dem_adj, snow_binary, dx=dx, verbose=False)\n",
    "            \n",
    "        # Save in DataFrame\n",
    "        df = pd.DataFrame({'RGIId': [rgi_id] * len(scs),\n",
    "                           'datetime': dts,\n",
    "                           'source': sources,\n",
    "                           'SLA_m': sla_originals,\n",
    "                           'SLA_lower_bound_m': sla_lower_bounds,\n",
    "                           'SLA_upper_bound_m': sla_upper_bounds})\n",
    "        \n",
    "        # Concatenate to results DataFrame\n",
    "        sla_bounds_df = pd.concat([sla_bounds_df, df], axis=0)\n",
    "    \n",
    "    # Save results to file\n",
    "    sla_bounds_df.reset_index(drop=True, inplace=True)\n",
    "    sla_bounds_df.to_csv(sla_bounds_fn, index=False)\n",
    "    print('SLA bounds saved to file:', sla_bounds_fn)\n",
    "    \n",
    "else:\n",
    "    sla_bounds_df = pd.read_csv(sla_bounds_fn)\n",
    "\n",
    "# Add column for total range and describe stats\n",
    "sla_bounds_df['SLA_bounds_range_m'] = np.abs(sla_bounds_df['SLA_upper_bound_m'] - sla_bounds_df['SLA_lower_bound_m'])\n",
    "plt.boxplot(sla_bounds_df['SLA_bounds_range_m'], showfliers=False)\n",
    "plt.show()\n",
    "\n",
    "sla_bounds_df['SLA_bounds_range_m'].describe()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results with an example calculation for supporting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example site ID\n",
    "rgi_id = 'RGI60-01.01104'\n",
    "epsg_utm = \"EPSG:32606\"\n",
    "\n",
    "# Load all AOIs\n",
    "aois_fn = os.path.join(scm_path, 'analysis', 'all_aois.shp')\n",
    "aois = gpd.read_file(aois_fn)\n",
    "# Add elevation range column\n",
    "aois['Zrange'] = aois['Zmax'] - aois['Zmin']\n",
    "# Merge with SLA bounds\n",
    "sla_bounds_df = sla_bounds_df.merge(aois[['RGIId', 'Zrange']], on='RGIId')\n",
    "\n",
    "# Load snow cover stats\n",
    "scs_fn = os.path.join(scm_path, 'study-sites', rgi_id, f\"{rgi_id}_snow_cover_stats.csv\")\n",
    "scs = pd.read_csv(scs_fn)\n",
    "scs = scs.loc[scs['AAR'] < 1].reset_index(drop=True) # remove rows where AAR = 1\n",
    "# Load DEM\n",
    "dem_fn = glob.glob(os.path.join(scm_path, 'study-sites', rgi_id, 'DEMs', '*.tif'))[0]\n",
    "dem = rxr.open_rasterio(dem_fn).isel(band=0)\n",
    "dem = xr.where((dem < -1e3) | (dem > 1e4), np.nan, dem)\n",
    "dem = dem.rio.write_crs(\"EPSG:4326\")\n",
    "# Load AOI\n",
    "aoi_fn = os.path.join(scm_path, 'study-sites', rgi_id, 'AOIs', f\"{rgi_id}_outline.shp\")\n",
    "aoi = gpd.read_file(aoi_fn)\n",
    "# Clip DEM to AOI\n",
    "dem = dem.rio.clip(aoi.geometry)\n",
    "# Choose an image with some masking and relatively low transient AAR for demonstration\n",
    "sc = scs.loc[(scs['datetime']=='2019-07-03T20:18:52') & (scs['source']=='Sentinel-2_SR')].reset_index(drop=True).iloc[0]\n",
    "# sc = scs.loc[(scs['AAR'] < 0.5) & (scs['source']=='Sentinel-2_SR')].reset_index(drop=True).iloc[0]\n",
    "classified_fn = glob.glob(os.path.join(scm_path, 'study-sites', rgi_id, 'classified', \n",
    "                                       f\"{sc['datetime'].replace('-', '').replace(':','')}_{rgi_id}_{sc['source']}_classified.nc\"))[0]\n",
    "classified = rxr.open_rasterio(classified_fn).squeeze()\n",
    "classified = xr.where(classified==-9999, np.nan, classified)\n",
    "classified = classified.rio.write_crs(\"EPSG:4326\")\n",
    "classified_utm = classified.rio.reproject(epsg_utm)\n",
    "classified_utm = xr.where(classified_utm > 1e30, np.nan, classified_utm)\n",
    "\n",
    "# Create binary snow image\n",
    "snow_binary = xr.where((classified==1) | (classified==2), 1, 0)\n",
    "snow_binary = xr.where(np.isnan(classified), np.nan, snow_binary) # re-insert no data values\n",
    "\n",
    "# Regrid DEM to classified image grid\n",
    "dem = dem.rio.reproject_match(classified)\n",
    "dem = xr.where(dem > 1e4, np.nan, dem)\n",
    "dem = dem.rio.write_crs(\"EPSG:4326\")\n",
    "dem_utm = dem.rio.reproject(epsg_utm)\n",
    "\n",
    "# Calculate lower and upper bounds of snowline altitude\n",
    "if sc['source']=='Landsat':\n",
    "    dx=30\n",
    "elif 'Sentinel-2' in sc['source']:\n",
    "    dx=10\n",
    "sla, sla_upper_bound, sla_lower_bound = calculate_sla_bounds(sc, dem, snow_binary, dx=dx, verbose=True)   \n",
    "dem_utm = xr.where(dem_utm > 1e30, np.nan, dem_utm)\n",
    "# Define colormap for classified images\n",
    "cmap_dict = {\"Snow\": \"#4eb3d3\",  \"Shadowed_snow\": \"#4eb3d3\", \"Ice\": \"#084081\", \"Rock\": \"#fe9929\", \"Water\": \"#969696\"}\n",
    "colors = []\n",
    "for key in list(cmap_dict.keys()):\n",
    "    color = list(matplotlib.colors.to_rgb(cmap_dict[key]))\n",
    "    if key=='Rock':\n",
    "        color += [0.5]\n",
    "    colors.append(color)\n",
    "cmap = matplotlib.colors.ListedColormap(colors)\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fontsize=11\n",
    "lw=1.5\n",
    "plt.rcParams.update({'font.size':fontsize, 'font.sans-serif': 'Arial'})\n",
    "gs = matplotlib.gridspec.GridSpec(3,2, height_ratios=[1, 1.5, 1.5])\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "ax = [fig.add_subplot(gs[0,0]), fig.add_subplot(gs[0,1]),\n",
    "      fig.add_subplot(gs[1,:]),\n",
    "      fig.add_subplot(gs[2,:])]\n",
    "\n",
    "# DEM\n",
    "im = ax[0].imshow(dem_utm.data, cmap='terrain', \n",
    "                  extent=(np.min(dem_utm.x)/1e3, np.max(dem_utm.x)/1e3, np.min(dem_utm.y)/1e3, np.max(dem_utm.y)/1e3))\n",
    "cbar = fig.colorbar(im, ax=ax[0], shrink=0.9, label='Elevation [m]')\n",
    "ax[0].set_xlabel('Easting [km]')\n",
    "ax[0].set_ylabel('Northing [km]')\n",
    "\n",
    "# classified image\n",
    "im = ax[1].imshow(classified_utm.data, cmap=cmap, clim=(0.5,5.5),\n",
    "                  extent=(np.min(classified_utm.x)/1e3, np.max(classified_utm.x)/1e3, np.min(classified_utm.y)/1e3, np.max(classified_utm.y)/1e3))\n",
    "cbar = fig.colorbar(im, ax=ax[1], shrink=0.9, ticks=[2, 3, 4, 5])\n",
    "cbar.ax.set_yticklabels(['Snow', 'Ice/firn', 'Rock', 'Water'])\n",
    "cbar.ax.set_ylim(1.5,5.5)\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_xlabel('Easting [km]')\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "# SLA contours\n",
    "x_mesh, y_mesh = np.meshgrid(np.divide(dem_utm.x.data, 1e3), np.divide(dem_utm.y.data, 1e3))\n",
    "for axis in ax[0:2]:\n",
    "    axis.contour(x_mesh, y_mesh, dem_utm.data, levels=[sla], colors='k', linewidth=lw)\n",
    "\n",
    "# histograms and bounds\n",
    "bin_edges = np.arange(700, 1481, step=10)\n",
    "bin_centers = (bin_edges[1:] + bin_edges[0:-1]) / 2\n",
    "# all elevations\n",
    "counts, _ = np.histogram(dem_utm.data, bins=bin_edges)\n",
    "areas = counts * dx**2 / 1e6 # km^2\n",
    "ax[2].bar(bin_centers, areas, width=bin_edges[1]-bin_edges[0], facecolor='gray', \n",
    "          edgecolor='k', alpha=0.5, linewidth=lw-1, label='All elevations')\n",
    "# snow-covered elevations\n",
    "dem_snow = xr.where(classified_utm==1, dem_utm, np.nan)\n",
    "counts, _ = np.histogram(dem_snow.data, bins=bin_edges)\n",
    "areas = counts * dx**2 / 1e6 # km^2\n",
    "ax[2].bar(bin_centers, areas, width=bin_edges[1]-bin_edges[0], facecolor=cmap_dict['Snow'], \n",
    "          edgecolor='k', alpha=1.0, linewidth=lw-1, label='Snow-covered elevations')\n",
    "ax[2].axvline(sla, color='k', linewidth=lw, label='Original SLA')\n",
    "ax[2].axvline(sla_lower_bound, color='k', linestyle='--', linewidth=lw, label='SLA lower bound')\n",
    "ax[2].axvline(sla_upper_bound, color='k', linestyle=':', linewidth=lw, label='SLA upper bound')\n",
    "ax[2].text(850, 0.28, \"Snow-covered area \\nbelow SLA = 0.78 km$^2$\", fontsize=9, ha='center',\n",
    "           bbox=dict(facecolor='w', edgecolor='None', alpha=0.7))\n",
    "ax[2].text(1350, 0.28, \"Snow-free area \\nabove SLA = 0.66 km$^2$\", fontsize=9, ha='center')\n",
    "ax[2].set_xlim(np.min(bin_edges)-20, np.max(bin_edges)+20)\n",
    "ax[2].set_xlabel('Elevation [m]')\n",
    "ax[2].set_ylabel('Area [km$^2$]')\n",
    "ax[2].legend(loc='upper left')\n",
    "\n",
    "# histogram of SLA ranges\n",
    "ax[3].hist(sla_bounds_df['SLA_bounds_range_m'], bins=np.linspace(0, 1000, num=101), \n",
    "           facecolor='gray', alpha=0.9, edgecolor='k', linewidth=0.5)\n",
    "range_median = np.nanmedian(sla_bounds_df['SLA_bounds_range_m'])\n",
    "ax[3].axvline(range_median, color='k', linewidth=lw)\n",
    "ax[3].text(160, 320, f\"Median SLA range = {int(np.round(range_median, -1))} m\", fontweight='bold')\n",
    "ax[3].set_xlabel('Range of all SLA bounds [m]')\n",
    "ax[3].set_ylabel('Counts')\n",
    "ax[3].set_xlim(0, 600)\n",
    "# add panel labels\n",
    "labels = ['a', 'b', 'c', 'd']\n",
    "for i, axis in enumerate(ax):\n",
    "    if i < 2:\n",
    "        xscale=0.85\n",
    "        yscale=0.9\n",
    "    else:\n",
    "        xscale=0.95\n",
    "        yscale=0.9\n",
    "    axis.text(xscale, yscale, labels[i], transform=axis.transAxes, fontsize=fontsize+4, fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure to file\n",
    "fig_fn = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/glacier-snow-cover-analysis/figures/figS2_SLA_uncertainties.png'\n",
    "fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "print('Figure saved to file:', fig_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(sla_bounds_df, x='Zrange', y='SLA_bounds_range_m', cmap='rocket', bins=50, cbar=True)\n",
    "plt.xlabel('Glacier elevation range [m]')\n",
    "plt.ylabel('Range in SLA bounds [m]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glacier-snow-cover-mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
