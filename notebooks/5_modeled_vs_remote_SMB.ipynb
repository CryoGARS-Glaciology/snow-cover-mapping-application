{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa19aea-f65a-4694-aa1b-1c1c24efbf58",
   "metadata": {},
   "source": [
    "# Estimate differences in modeled and remotely-sensed SMB\n",
    "\n",
    "1. Monthly snowline altitudes (SLAs)\n",
    "2. Equilibrium line altitudes (ELAs)\n",
    "3. Modeled surface mass balance (SMB) at the remotely-sensed snowline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10b4fc-0d6f-45af-b2ac-9c92269f5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde12fe-197d-41a7-8ec0-5b0d34956a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for inputs and outputs\n",
    "scm_dir = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "# Grab modeled SMB file names\n",
    "mod_smb_dir = os.path.join(scm_dir, 'Rounce_et_al_2023', 'glac_SMB_binned')\n",
    "# Load glacier boundaries for RGI IDs\n",
    "aois_fn = os.path.join(scm_dir, 'analysis', 'all_aois.shp')\n",
    "aois = gpd.read_file(aois_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc2430",
   "metadata": {},
   "source": [
    "## 1. Monthly snowline altitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2c326-e946-4ec3-b453-2149a351f311",
   "metadata": {},
   "source": [
    "### Modeled SLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b26c4-b13f-4f05-b233-bd6e773bfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for linearly extrapolating the ELA when modeled SMB < 0 everywhere\n",
    "def linear_fit(x, m, b):\n",
    "    return m*x + b\n",
    "    \n",
    "def extrapolate_ela_linear(X,y, Iend=8):\n",
    "    # optimize the linear fit\n",
    "    p, e = optimize.curve_fit(linear_fit, X[0:Iend+1], y[0:Iend+1])\n",
    "    # extrapolate where y=0\n",
    "    ela = linear_fit(0, *p)\n",
    "    return ela\n",
    "\n",
    "# Check if file already exists\n",
    "slas_mod_fn = os.path.join(scm_dir, 'analysis', 'monthly_SLAs_modeled.csv')\n",
    "if not os.path.exists(slas_mod_fn):\n",
    "    # load binned model data\n",
    "    bin_fns = sorted(glob.glob(os.path.join(mod_smb_dir, '*.nc')))\n",
    "    \n",
    "    # remove binned file names for sites without snow cover observations\n",
    "    aoi_ids = [x[7:] for x in sorted(aois['RGIId'].drop_duplicates().values)]\n",
    "    bin_fns = [x for x in bin_fns if os.path.basename(x)[0:7] in aoi_ids]\n",
    "\n",
    "    # initialize dataframe for results\n",
    "    slas_mod = pd.DataFrame()\n",
    "\n",
    "    # iterate over binned file names\n",
    "    i=0\n",
    "    for bin_fn in tqdm(bin_fns):\n",
    "        # open binned data\n",
    "        bin = xr.open_dataset(bin_fn)\n",
    "        rgi_id = bin.RGIId.data[0] # grab RGI ID\n",
    "\n",
    "        # grab data variables\n",
    "        h = bin.bin_surface_h_initial.data[0] # surface elevation [m]\n",
    "        b_sum = np.zeros((len(bin.time.data), len(h))) # cumulative SMB\n",
    "        times = [np.datetime64(x) for x in bin.time.data] # datetimes\n",
    "        months = list(pd.DatetimeIndex(times).month) # months of each datetime\n",
    "        slas = np.zeros(len(times)) # initialize SLAs\n",
    "\n",
    "        # iterate over each time period\n",
    "        for j, time in enumerate(times):\n",
    "            # subset binned data to time\n",
    "            bin_time = bin.isel(time=j)\n",
    "            # grab the SMB \n",
    "            b_sum[j,:] = bin_time.bin_massbalclim_monthly.data[0]\n",
    "            # add the previous SMB (restart the count in October)\n",
    "            if months[j] != 10: \n",
    "                b_sum[j,:] += b_sum[j-1,:]\n",
    "            # If all SMB > 0, ELA = minimum elevation\n",
    "            if all(b_sum[j,:] > 0):\n",
    "                slas[j] = np.min(h)\n",
    "            # If SMB is > 0 and < 0 in some places, linearly interpolate ELA\n",
    "            elif any(b_sum[j,:] < 0) & any(b_sum[j,:] > 0):\n",
    "                slas[j] = np.interp(0, np.flip(b_sum[j,:]), np.flip(h))\n",
    "            # If SMB < 0 everywhere, fit a piecewise linear fit and extrapolate for SMB=0\n",
    "            elif all(b_sum[j,:] < 0):\n",
    "                X, y = b_sum[j,:], h\n",
    "                slas[j] = extrapolate_ela_linear(X, y, Iend=5)\n",
    "            else:\n",
    "                print('issue')\n",
    "\n",
    "        # compile in dataframe\n",
    "        df = pd.DataFrame({'Date': times,\n",
    "                           'SLA_mod_m': slas})\n",
    "        \n",
    "        # Because each SMB value represents the total SMB for each month, add 1 month to the dates\n",
    "        df['Date'] = df['Date'] + pd.DateOffset(months=1)\n",
    "        df['RGIId'] = rgi_id\n",
    "\n",
    "        slas_mod = pd.concat([slas_mod, df])\n",
    "            \n",
    "        i+=1\n",
    "\n",
    "    # Rearrange columns\n",
    "    slas_mod = slas_mod[['RGIId', 'Date', 'SLA_mod_m']]\n",
    "    # Save to file\n",
    "    slas_mod.to_csv(slas_mod_fn, index=False)\n",
    "    print('Modeled monthly SLAs saved to file:', slas_mod_fn)\n",
    "\n",
    "else:\n",
    "    \n",
    "    slas_mod = pd.read_csv(slas_mod_fn)\n",
    "    slas_mod['Date'] = pd.DatetimeIndex(slas_mod['Date'])\n",
    "    print('Modeled monthly SLAs loaded from file.')\n",
    "\n",
    "slas_mod.reset_index(drop=True, inplace=True)\n",
    "slas_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d98cc",
   "metadata": {},
   "source": [
    "### Remotely-sensed SLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c287520",
   "metadata": {},
   "outputs": [],
   "source": [
    "slas_obs_fn = os.path.join(scm_dir, 'analysis', 'monthly_SLAs_observed.csv')\n",
    "if not os.path.exists(slas_obs_fn):\n",
    "    # iterate over RGI IDs\n",
    "    slas_obs = pd.DataFrame()\n",
    "    for rgi_id in tqdm(sorted(aois['RGIId'].drop_duplicates().values)):\n",
    "        scs_fn = os.path.join(scm_dir, 'study-sites', rgi_id, f'{rgi_id}_snow_cover_stats.csv')\n",
    "        scs = pd.read_csv(scs_fn)\n",
    "        scs['datetime'] = pd.to_datetime(scs['datetime'], format='mixed')\n",
    "        scs['Year'] = scs['datetime'].dt.year\n",
    "        scs['Month'] = scs['datetime'].dt.month\n",
    "        scs['Day'] = scs['datetime'].dt.day\n",
    "        # Filter data to within one week of the first of each month\n",
    "        scs_filtered = scs[(scs['Day'] >= 25) | (scs['Day'] <= 7)]\n",
    "        # Function to identify the row closest to the first of each month\n",
    "        Imonths = []\n",
    "        for year, month in scs_filtered[['Year', 'Month']].drop_duplicates().values:\n",
    "            first_of_month = pd.Timestamp(year=year, month=month, day=1)\n",
    "            # identify closest observation to this date\n",
    "            scs_filtered.loc[:, 'diff'] = np.abs(scs_filtered.loc[:, 'datetime'] - first_of_month)\n",
    "            Imonths.append(scs_filtered['diff'].idxmin())\n",
    "        scs_monthly = scs.iloc[Imonths]\n",
    "\n",
    "        # concatenate to full dataframe\n",
    "        slas_obs = pd.concat([slas_obs, scs_monthly])\n",
    "\n",
    "    # add a \"Date\" column that is first of month\n",
    "    slas_obs['Date'] = pd.to_datetime(slas_obs[['Year', 'Month']].assign(Day=1))\n",
    "\n",
    "    # select relevant columns\n",
    "    slas_obs.rename(columns={'ELA_from_AAR_m': 'SLA_obs_m'}, inplace=True)\n",
    "    slas_obs = slas_obs[['RGIId', 'Date', 'SLA_obs_m']]\n",
    "    slas_obs.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # save to file\n",
    "    slas_obs.to_csv(slas_obs_fn, index=False)\n",
    "    print('Remotely-sensed monthly SLAs saved to file:', slas_obs_fn)\n",
    "\n",
    "else:  \n",
    "    slas_obs = pd.read_csv(slas_obs_fn)\n",
    "    slas_obs['Date'] = pd.to_datetime(slas_obs['Date'])\n",
    "    print('Remotely-sensed monthly SLAs loaded from file.')\n",
    "\n",
    "slas_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512e6fe",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7383829",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab minimum glacier elevations for standardizing ###\n",
    "# Define output file name\n",
    "min_sla_obs_fn = os.path.join(scm_dir, 'analysis', 'minimum_glacier_elevations_observed.csv')\n",
    "if not os.path.exists(min_sla_obs_fn):\n",
    "    # load AOIs\n",
    "    aois = gpd.read_file(aois_fn)\n",
    "    min_slas_obs = pd.DataFrame()\n",
    "    # Iterate over sites\n",
    "    for rgi_id in tqdm(aois['RGIId'].drop_duplicates().values):\n",
    "        # Load snowlines\n",
    "        scs_fn = os.path.join(scm_dir, 'study-sites', rgi_id, f'{rgi_id}_snow_cover_stats.csv')\n",
    "        scs = pd.read_csv(scs_fn)\n",
    "        # Remove any wonky values\n",
    "        scs.loc[np.abs(scs['ELA_from_AAR_m']) > 1e10] = np.nan\n",
    "        # Get minimum snowline altitude\n",
    "        min_sla = scs['ELA_from_AAR_m'].min()\n",
    "        # Add to dataframe\n",
    "        df = pd.DataFrame({'RGIId': [rgi_id], 'SLA_obs_m_min': [min_sla]})\n",
    "        min_slas_obs = pd.concat([min_slas_obs, df], axis=0)\n",
    "\n",
    "    # Save to file\n",
    "    min_slas_obs.reset_index(drop=True, inplace=True)\n",
    "    min_slas_obs.to_csv(min_sla_obs_fn, index=False)\n",
    "    print('Minimum remotely-sensed glacier elevations saved to file:', min_sla_obs_fn)\n",
    "    \n",
    "else:\n",
    "    min_slas_obs = pd.read_csv(min_sla_obs_fn)\n",
    "    print('Minimum remotely-sensed glacier elevations loaded.')\n",
    "\n",
    "min_slas_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file\n",
    "slas_merged_fn = os.path.join(scm_dir, 'analysis', 'monthly_SLAs_modeled_observed_merged.csv')\n",
    "if not os.path.exists(slas_merged_fn):\n",
    "\n",
    "    # Merge modeled and remotely-sensed ELAs\n",
    "    slas_merged = slas_mod[['RGIId', 'Date', 'SLA_mod_m']].merge(slas_obs[['RGIId', 'Date', 'SLA_obs_m']],\n",
    "                                                                 on=['RGIId', 'Date'])\n",
    "    # Remove 2023 values (no modeled data in 2023)\n",
    "    slas_merged = slas_merged.loc[pd.DatetimeIndex(slas_merged['Date']).year < 2023]\n",
    "    \n",
    "    # Remove observations outside May - September\n",
    "    slas_merged = slas_merged.loc[(pd.DatetimeIndex(slas_merged['Date']).month >=5) \n",
    "                                  & (pd.DatetimeIndex(slas_merged['Date']).month <=9)]\n",
    "\n",
    "    # Subtract the minimum snowline altitudes to mitigate datum issues, s.t. SLAs are w.r.t. 0 m. \n",
    "    for rgi_id in slas_merged['RGIId'].drop_duplicates().values:\n",
    "        min_sla_obs = min_slas_obs.loc[min_slas_obs['RGIId']==rgi_id, 'SLA_obs_m_min'].values[0]\n",
    "        slas_merged.loc[slas_merged['RGIId']==rgi_id, 'SLA_obs_m'] -= min_sla_obs\n",
    "        min_sla_mod = slas_mod.loc[slas_mod['RGIId']==rgi_id, 'SLA_mod_m'].min()\n",
    "        slas_merged.loc[slas_merged['RGIId']==rgi_id, 'SLA_mod_m'] -= min_sla_mod\n",
    "\n",
    "    # Save results\n",
    "    slas_merged.to_csv(slas_merged_fn, index=False)\n",
    "    print('Merged monthly SLAs saved to file:', slas_merged_fn)\n",
    "\n",
    "else:\n",
    "    slas_merged = pd.read_csv(slas_merged_fn)\n",
    "    print('Merged monthly SLAs loaded.')\n",
    "\n",
    "\n",
    "slas_merged['SLA_mod-obs_m'] = slas_merged['SLA_mod_m'] - slas_merged['SLA_obs_m']\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ax.hist(slas_merged['SLA_mod-obs_m'], bins=50)\n",
    "ax.set_xlabel('SLA$_{mod}$ - SLA$_{obs}$ [m]')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('\\nDifference stats:')\n",
    "print(f'Mean diff = {np.nanmean((slas_merged[\"SLA_mod-obs_m\"]).values)} m')\n",
    "print(f'Std. diff = {np.nanstd((slas_merged[\"SLA_mod-obs_m\"]).values)} m')\n",
    "print(f'Median diff = {np.nanmedian((slas_merged[\"SLA_mod-obs_m\"]).values)} m')\n",
    "print(f'MAD diff = {MAD((slas_merged[\"SLA_mod-obs_m\"]).values, nan_policy=\"omit\")} m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2ecd9",
   "metadata": {},
   "source": [
    "## 2. ELAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad5f0a-21a1-4cc9-9ae5-0d82dc296576",
   "metadata": {},
   "source": [
    "### Modeled ELAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c401e-1035-42af-a623-2d6d03f8365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "elas_mod_fn = os.path.join(scm_dir, 'analysis', 'annual_ELAs_modeled.csv')\n",
    "if not os.path.exists(elas_mod_fn):\n",
    "    # Add Year column\n",
    "    slas_mod['Year'] = pd.DatetimeIndex(slas_mod['Date']).year\n",
    "    # Identify the row of maximum ELA for each site and each year\n",
    "    Imax = slas_mod.groupby(by=['RGIId', 'Year'])['SLA_mod_m'].idxmax().values\n",
    "    elas_mod = slas_mod.iloc[Imax].reset_index(drop=True)\n",
    "    elas_mod.rename(columns={'SLA_mod_m': 'ELA_mod_m'}, inplace=True)\n",
    "    # Reorder columns\n",
    "    elas_mod = elas_mod[['RGIId', 'Date', 'Year', 'ELA_mod_m']]\n",
    "    # Save to file\n",
    "    elas_mod.to_csv(elas_mod_fn, index=False)\n",
    "    print('Modeled annual ELAs saved to file:', elas_mod_fn)\n",
    "else:\n",
    "    elas_mod = pd.read_csv(elas_mod_fn)\n",
    "    elas_mod['Date'] = pd.to_datetime(elas_mod['Date'])\n",
    "    print('Modeled annual ELAs loaded from file.')\n",
    "    \n",
    "elas_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a61b4",
   "metadata": {},
   "source": [
    "### Remotely-sensed ELAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "elas_obs_fn = os.path.join(scm_dir, 'analysis', 'annual_ELAs_observed.csv')\n",
    "if not os.path.exists(elas_obs_fn):\n",
    "    # iterate over sites\n",
    "    elas_obs = pd.DataFrame()\n",
    "    for rgi_id in tqdm(slas_obs['RGIId'].drop_duplicates().values):\n",
    "        # Subset to site\n",
    "        slas_obs_site = slas_obs.loc[slas_obs['RGIId']==rgi_id].reset_index(drop=True)\n",
    "        # Subset to 2016–2023\n",
    "        slas_obs_site = slas_obs_site.loc[slas_obs_site['Date'].dt.year >= 2016].reset_index(drop=True)\n",
    "        # identify maximum annual SLA\n",
    "        imax = slas_obs_site.groupby(slas_obs_site['Date'].dt.year)['SLA_obs_m'].idxmax().values\n",
    "        df = slas_obs_site.iloc[imax]\n",
    "        # concatenate to full dataframe\n",
    "        elas_obs = pd.concat([elas_obs, df])\n",
    "    elas_obs.reset_index(drop=True, inplace=True)\n",
    "    elas_obs.rename(columns={'SLA_obs_m': 'ELA_obs_m'}, inplace=True)\n",
    "\n",
    "    # save to file\n",
    "    elas_obs.to_csv(elas_obs_fn, index=False)\n",
    "    print('Remotely-sensed ELAs saved to file:', elas_obs_fn)\n",
    "\n",
    "else:\n",
    "    elas_obs = pd.read_csv(elas_obs_fn)\n",
    "    elas_obs['Date'] = pd.to_datetime(elas_obs['Date'])\n",
    "    print('Remotely-sensed ELAs loaded from file.')\n",
    "\n",
    "elas_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739099a-00f6-428a-96ed-63a9a7fd655c",
   "metadata": {},
   "source": [
    "### Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bb9a5-a22f-41a1-9f5c-31f002300a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file name\n",
    "elas_merged_fn = os.path.join(scm_dir, 'analysis', 'annual_ELAs_modeled_observed_merged.csv')\n",
    "if not os.path.exists(elas_merged_fn):\n",
    "\n",
    "    # Merge modeled and remotely-sensed modeled ELAs\n",
    "    elas_obs['Year'] = elas_obs['Date'].dt.year\n",
    "    elas_merged = elas_obs[['RGIId', 'Year', 'ELA_obs_m']].merge(elas_mod[['RGIId', 'Year', 'ELA_mod_m']],\n",
    "                                                                 on=['RGIId', 'Year'])\n",
    "    \n",
    "    # Subset to 2016–2022 (no modeled data in 2023)\n",
    "    elas_merged = elas_merged.loc[(elas_merged['Year'] >= 2016) \n",
    "                                                & (elas_merged['Year'] < 2023)]\n",
    "        \n",
    "    # Save results\n",
    "    elas_merged.to_csv(elas_merged_fn, index=False)\n",
    "    print('Merged annual ELAs saved to file:', elas_merged_fn)\n",
    "\n",
    "else:\n",
    "    elas_merged = pd.read_csv(elas_merged_fn)\n",
    "    print('Merged annual ELAs loaded.')\n",
    "    \n",
    "# Calculate difference\n",
    "elas_merged['ELA_mod-obs_m'] = elas_merged['ELA_mod_m'] - elas_merged['ELA_obs_m']\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(elas_merged['ELA_mod-obs_m'], bins=50)\n",
    "ax.set_xlabel('ELA$_{mod}$ - ELA$_{obs}$ [m]')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "print('\\nDifference stats:')\n",
    "print(f\"Mean diff = {np.nanmean(elas_merged['ELA_mod-obs_m'])} m\")\n",
    "print(f\"Std. diff = {np.nanstd(elas_merged['ELA_mod-obs_m'])} m\")\n",
    "print(f\"Median diff = {np.nanmedian(elas_merged['ELA_mod-obs_m'])} m\")\n",
    "print(f\"MAD diff = {MAD(elas_merged['ELA_mod-obs_m'], nan_policy='omit')} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389089dc",
   "metadata": {},
   "source": [
    "## 3. Modeled SMB at remotely-sensed snowlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b936a9e-befa-434a-ab15-a3ef98b6d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "sla_obs_smb_mod_fn = os.path.join(scm_dir, 'analysis', 'modeled_SMB_at_observed_SLA.csv')\n",
    "if not os.path.exists(sla_obs_smb_mod_fn):\n",
    "    # Intialize dataframe\n",
    "    sla_obs_smb_mod = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over RGI IDs\n",
    "    for rgi_id in tqdm(aois['RGIId'].drop_duplicates().values):\n",
    "        mod_smb_fn = glob.glob(os.path.join(mod_smb_dir, f\"{rgi_id.split('RGI60-0')[1]}*.nc\"))[0]\n",
    "        mod_smb = xr.open_dataset(mod_smb_fn)\n",
    "        slas_obs_site = slas_obs.loc[slas_obs['RGIId']==rgi_id]\n",
    "\n",
    "        # grab data variables\n",
    "        h = mod_smb.bin_surface_h_initial.data[0] # surface elevation [m]\n",
    "        b_sum = np.zeros((len(mod_smb.time.data), len(h))) # cumulative SMB\n",
    "        dts = [pd.Timestamp(np.datetime64(x)) for x in mod_smb.time.data] # datetimes\n",
    "        months = list(pd.DatetimeIndex(times).month) # months of each datetime\n",
    "\n",
    "        # iterate over each time period\n",
    "        for j, dt in enumerate(dts):\n",
    "            # subset binned data to time\n",
    "            mod_smb_time = mod_smb.isel(time=j)\n",
    "            # grab the SMB \n",
    "            b_sum[j,:] = mod_smb_time.bin_massbalclim_monthly.data[0]\n",
    "            # add the previous SMB (restart the count in October)\n",
    "            if months[j] != 10: \n",
    "                b_sum[j,:] += b_sum[j-1,:]\n",
    "            # grab observed SLA\n",
    "            sla = slas_obs_site.loc[slas_obs_site['Date']==dt, 'SLA_obs_m'].values\n",
    "            if len(sla) > 0:\n",
    "                # interpolate SMB at SLA\n",
    "                smb_sla = np.interp(sla[0], h, b_sum[j,:])\n",
    "                df = pd.DataFrame({'RGIId': [rgi_id],\n",
    "                                   'Date': [dt],\n",
    "                                   'SMB_at_SLA_mwe': [smb_sla]})\n",
    "                # add to full dataframe\n",
    "                sla_obs_smb_mod = pd.concat([sla_obs_smb_mod, df], axis=0)\n",
    "                \n",
    "    # Save to file\n",
    "    sla_obs_smb_mod.reset_index(drop=True, inplace=True)\n",
    "    sla_obs_smb_mod.to_csv(sla_obs_smb_mod_fn, index=False)\n",
    "    print('SMB at SLA saved to file:', sla_obs_smb_mod_fn)\n",
    "\n",
    "else:\n",
    "    sla_obs_smb_mod = pd.read_csv(sla_obs_smb_mod_fn)\n",
    "    print('SMB at SLA loaded from file.')\n",
    "    \n",
    "sla_obs_smb_mod\n",
    "    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c2162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glacier-snow-cover-mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
