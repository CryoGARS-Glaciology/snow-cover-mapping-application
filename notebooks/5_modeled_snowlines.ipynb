{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa19aea-f65a-4694-aa1b-1c1c24efbf58",
   "metadata": {},
   "source": [
    "# Estimate modeled snowline altitudes and ELAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10b4fc-0d6f-45af-b2ac-9c92269f5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "from tqdm.auto import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde12fe-197d-41a7-8ec0-5b0d34956a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load remotely-sensed ELAs\n",
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "obs_slas_monthly_fn = os.path.join(scm_path, 'analysis', 'monthly_SLAs_observed.csv')\n",
    "obs_slas_monthly = pd.read_csv(obs_slas_monthly_fn)\n",
    "obs_slas_monthly['Date'] = pd.to_datetime(obs_slas_monthly['Date'])\n",
    "obs_elas_annual_fn = os.path.join(scm_path, 'analysis', 'annual_ELAs_observed.csv')\n",
    "obs_elas_annual = pd.read_csv(obs_elas_annual_fn)\n",
    "obs_elas_annual['Date'] = pd.to_datetime(obs_elas_annual['Date'])\n",
    "\n",
    "# Grab modeled SMB file names\n",
    "modeled_path = os.path.join(scm_path, 'Rounce_et_al_2023', 'binned')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2c326-e946-4ec3-b453-2149a351f311",
   "metadata": {},
   "source": [
    "## Estimate modeled snowline altitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25d4a5-f302-47bd-8838-6b94ae1515d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for linearly extrapolating the ELA when modeled SMB < 0 everywhere\n",
    "def linear_fit(x, m, b):\n",
    "    return m*x + b\n",
    "    \n",
    "def extrapolate_ela_linear(X,y, Iend=8):\n",
    "    # optimize the linear fit\n",
    "    p, e = optimize.curve_fit(linear_fit, X[0:Iend+1], y[0:Iend+1])\n",
    "    # extrapolate where y=0\n",
    "    ela = linear_fit(0, *p)\n",
    "    return ela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b26c4-b13f-4f05-b233-bd6e773bfdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Monthly snowline altitudes\n",
    "mod_slas_monthly_fn = os.path.join(scm_path, 'analysis', 'monthly_SLAs_modeled.csv')\n",
    "if os.path.exists(mod_slas_monthly_fn):\n",
    "    mod_slas_monthly = pd.read_csv(mod_slas_monthly_fn)\n",
    "    mod_slas_monthly['Date'] = pd.DatetimeIndex(mod_slas_monthly['Date'])\n",
    "    print('Modeled monthly SLAs loaded from file.')\n",
    "else:\n",
    "    \n",
    "    # load binned model data\n",
    "    bin_fns = sorted(glob.glob(os.path.join(modeled_path, '*.nc')))\n",
    "    \n",
    "    # remove binned file names for sites without snow cover observations\n",
    "    aoi_ids = [x[7:] for x in sorted(aois['RGIId'].drop_duplicates().values)]\n",
    "    bin_fns = [x for x in bin_fns if os.path.basename(x)[0:7] in aoi_ids]\n",
    "\n",
    "    # initialize dataframe for results\n",
    "    mod_slas_monthly = pd.DataFrame()\n",
    "\n",
    "    # iterate over binned file names\n",
    "    i=0\n",
    "    for bin_fn in tqdm(bin_fns):\n",
    "        # open binned data\n",
    "        bin = xr.open_dataset(bin_fn)\n",
    "        rgi_id = bin.RGIId.data[0] # grab RGI ID\n",
    "\n",
    "        # grab data variables\n",
    "        h = bin.bin_surface_h_initial.data[0] # surface elevation [m]\n",
    "        b_sum = np.zeros((len(bin.time.data), len(h))) # cumulative SMB\n",
    "        times = [np.datetime64(x) for x in bin.time.data] # datetimes\n",
    "        months = list(pd.DatetimeIndex(times).month) # months of each datetime\n",
    "        elas = np.zeros(len(times)) # initialize transient ELAs\n",
    "\n",
    "        # iterate over each time period\n",
    "        for j, time in enumerate(times):\n",
    "            # subset binned data to time\n",
    "            bin_time = bin.isel(time=j)\n",
    "            # grab the SMB \n",
    "            b_sum[j,:] = bin_time.bin_massbalclim_monthly.data[0]\n",
    "            # add the previous SMB (restart the count in October)\n",
    "            if months[j] != 10: \n",
    "                b_sum[j,:] += b_sum[j-1,:]\n",
    "            # If all SMB > 0, ELA = minimum elevation\n",
    "            if all(b_sum[j,:] > 0):\n",
    "                elas[j] = np.min(h)\n",
    "            # If SMB is > 0 and < 0 in some places, linearly interpolate ELA\n",
    "            elif any(b_sum[j,:] < 0) & any(b_sum[j,:] > 0):\n",
    "                elas[j] = np.interp(0, np.flip(b_sum[j,:]), np.flip(h))\n",
    "            # If SMB < 0 everywhere, fit a piecewise linear fit and extrapolate for SMB=0\n",
    "            elif all(b_sum[j,:] < 0):\n",
    "                X, y = b_sum[j,:], h\n",
    "                elas[j] = extrapolate_ela_linear(X, y, Iend=5)\n",
    "            else:\n",
    "                print('issue')\n",
    "\n",
    "        # compile in dataframe\n",
    "        df = pd.DataFrame({'Date': times,\n",
    "                           'ELA_m': elas})\n",
    "        \n",
    "        # Because each SMB value represents the total SMB for each month, add 1 month to the dates\n",
    "        df['Date'] = df['Date'] + pd.DateOffset(months=1)\n",
    "        df['RGIId'] = rgi_id\n",
    "\n",
    "        # Add ERA5 data for each date\n",
    "        eras_site = eras.loc[eras['RGIId']==rgi_id]\n",
    "        eras_site = eras_site[['Date', 'cumulative_positive_degree_days', 'cumulative_snowfall_sum']]\n",
    "        df = df.merge(eras_site, on='Date')\n",
    "        mod_slas_monthly = pd.concat([mod_slas_monthly, df])\n",
    "            \n",
    "        i+=1\n",
    "\n",
    "    # Rearrange columns\n",
    "    mod_slas_monthly = mod_slas_monthly[['RGIId', 'Date', 'ELA_m', \n",
    "                                         'cumulative_positive_degree_days', \n",
    "                                         'cumulative_snowfall_sum']]\n",
    "    # save to file\n",
    "    mod_slas_monthly.to_csv(mod_slas_monthly_fn, index=False)\n",
    "    print('Modeled monthly SLAs saved to file:', mod_elas_monthly_fn)\n",
    "\n",
    "mod_slas_monthly.reset_index(drop=True, inplace=True)\n",
    "mod_slas_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad5f0a-21a1-4cc9-9ae5-0d82dc296576",
   "metadata": {},
   "source": [
    "## Calculate modeled ELAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c401e-1035-42af-a623-2d6d03f8365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Annual ELAs\n",
    "mod_elas_annual_fn = os.path.join(scm_path, 'analysis', 'annual_ELAs_modeled.csv')\n",
    "if os.path.exists(mod_elas_annual_fn):\n",
    "    mod_elas_annual = pd.read_csv(mod_elas_annual_fn)\n",
    "    mod_elas_annual['Date'] = pd.to_datetime(mod_elas_annual['Date'])\n",
    "    print('Modeled annual ELAs loaded from file.')\n",
    "else:\n",
    "    # Add Year column\n",
    "    mod_elas_monthly['Year'] = pd.DatetimeIndex(mod_elas_monthly['Date']).year\n",
    "    # Identify the row of maximum ELA for each site and each year\n",
    "    Imax = mod_elas_monthly.groupby(by=['RGIId', 'Year'])['ELA_m'].idxmax().values\n",
    "    mod_elas_annual = mod_elas_monthly.iloc[Imax].reset_index(drop=True)\n",
    "    # Reorder columns\n",
    "    mod_elas_monthly = mod_elas_monthly[['RGIId', 'Date', 'Year', 'ELA_m', \n",
    "                                         'cumulative_positive_degree_days',\n",
    "                                         'cumulative_snowfall_sum']]\n",
    "    # Save to file\n",
    "    mod_elas_annual.to_csv(mod_elas_annual_fn, index=False)\n",
    "    print('Modeled annual ELAs saved to file:', mod_elas_annual_fn)\n",
    "    \n",
    "mod_elas_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31240e35-ee68-4674-aec3-e3b82d3453f7",
   "metadata": {},
   "source": [
    "## Difference modeled to remotely-sensed snowlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c1536-b4fe-43c0-ae67-a08ed73c9e5d",
   "metadata": {},
   "source": [
    "### Calculate minimum remotely-sensed snowline altitudes for standardizing elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271351ea-bb12-44c9-b0ff-a06c6069660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file name\n",
    "min_obs_sla_fn = os.path.join(scm_path, 'analysis', 'minimum_remotely-sensed_snowline_altitudes.csv')\n",
    "if not os.path.exists(min_obs_sla_fn):\n",
    "    min_obs_sla = pd.DataFrame()\n",
    "    # Iterate over sites\n",
    "    for rgi_id in tqdm(obs_elas_monthly['RGIId'].drop_duplicates().values):\n",
    "        # Load snowlines\n",
    "        scs = pd.DataFrame()\n",
    "        sc_fns = sorted(glob.glob(os.path.join(scm_path, 'study-sites', rgi_id, 'imagery', 'snowlines', '*.csv')))\n",
    "        for fn in sc_fns:\n",
    "            sc = pd.read_csv(fn)\n",
    "            scs = pd.concat([scs, sc], axis=0)\n",
    "        # Remove any wonky values\n",
    "        scs.loc[np.abs(scs['ELA_from_AAR_m']) > 1e10] = np.nan\n",
    "        # Get minimum snowline altitude\n",
    "        min_sla = scs['ELA_from_AAR_m'].min()\n",
    "        # Add to dataframe\n",
    "        df = pd.DataFrame({'RGIId': [rgi_id], 'SLA_min_m': [min_sla]})\n",
    "        min_obs_sla = pd.concat([min_obs_sla, df], axis=0)\n",
    "\n",
    "    # Save to file\n",
    "    min_obs_sla.reset_index(drop=True, inplace=True)\n",
    "    min_obs_sla.to_csv(min_obs_sla_fn, index=False)\n",
    "    print('Minimum snowline altitudes saved to file:', min_obs_sla_fn)\n",
    "    \n",
    "else:\n",
    "    min_obs_sla = pd.read_csv(min_obs_sla_fn)\n",
    "    print('Minimum snowline altitudes loaded.')\n",
    "\n",
    "min_obs_sla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9b597-ae38-4675-b430-83ac106b51f2",
   "metadata": {},
   "source": [
    "### Monthly snowline altitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a56eb8-b54a-47f3-9231-212b06156fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file\n",
    "slas_monthly_merged_fn = os.path.join(scm_path, 'analysis', 'monthly_SLAs_modeled_observed_merged.csv')\n",
    "if not os.path.exists(slas_monthly_merged_fn):\n",
    "\n",
    "    # Merge modeled and remotely-sensed ELAs\n",
    "    slas_monthly_merged = mod_slas_monthly[['RGIId', 'Date', 'ELA_m']].merge(obs_slas_monthly[['RGIId', 'Date', 'ELA_from_AAR_m']], \n",
    "                                                                             on=['RGIId', 'Date'])\n",
    "    # Remove 2023 values (no modeled data in 2023)\n",
    "    slas_monthly_merged = slas_monthly_merged.loc[pd.DatetimeIndex(slas_monthly_merged['Date']).year < 2023]\n",
    "    \n",
    "    # Remove observations outside May - September\n",
    "    slas_monthly_merged = slas_monthly_merged.loc[(pd.DatetimeIndex(slas_monthly_merged['Date']).month >=5) \n",
    "                                                & (pd.DatetimeIndex(slas_monthly_merged['Date']).month <=9)]\n",
    "    \n",
    "    # Rename columns\n",
    "    slas_monthly_merged.rename(columns={'ELA_m': 'ELA_mod_m', 'ELA_from_AAR_m': 'ELA_obs_m'}, inplace=True)\n",
    "\n",
    "    # Subtract the minimum snowline altitudes to mitigate datum issues, s.t. ELAs are w.r.t. 0 m. \n",
    "    for rgi_id in slas_monthly_merged['RGIId'].drop_duplicates().values:\n",
    "        min_sla_obs = min_obs_sla.loc[min_obs_sla['RGIId']==rgi_id, 'SLA_min_m'].values[0]\n",
    "        slas_monthly_merged.loc[slas_monthly_merged['RGIId']==rgi_id, 'ELA_obs_m'] -= min_sla_obs\n",
    "        min_sla_mod = mod_slas_monthly.loc[mod_slas_monthly['RGIId']==rgi_id, 'ELA_m'].min()\n",
    "        slas_monthly_merged.loc[slas_monthly_merged['RGIId']==rgi_id, 'ELA_mod_m'] -= min_sla_mod\n",
    "\n",
    "    # Calculate differences\n",
    "    slas_monthly_merged['ELA_obs-mod_m'] = slas_monthly_merged['ELA_obs_m'] - slas_monthly_merged['ELA_mod_m']\n",
    "\n",
    "    # Save results\n",
    "    slas_monthly_merged.to_csv(slas_monthly_merged_fn, index=False)\n",
    "    print('Merged monthly SLAs saved to file:', slas_monthly_merged_fn)\n",
    "\n",
    "else:\n",
    "    slas_monthly_merged = pd.read_csv(slas_monthly_merged_fn)\n",
    "    print('Merged monthly SLAs loaded.')\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ax.hist(slas_monthly_merged['ELA_obs-mod_m'], bins=50)\n",
    "ax.set_xlabel('Snowline$_{obs}$ - Snowline$_{mod}$ [m]')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('\\nDifference stats:')\n",
    "print(f'Mean diff = {np.nanmean((slas_monthly_merged[\"ELA_obs-mod_m\"]).values)} m')\n",
    "print(f'Std. diff = {np.nanstd((slas_monthly_merged[\"ELA_obs-mod_m\"]).values)} m')\n",
    "print(f'Median diff = {np.nanmedian((slas_monthly_merged[\"ELA_obs-mod_m\"]).values)} m')\n",
    "print(f'MAD diff = {MAD((slas_monthly_merged[\"ELA_obs-mod_m\"]).values, nan_policy=\"omit\")} m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739099a-00f6-428a-96ed-63a9a7fd655c",
   "metadata": {},
   "source": [
    "### Annual ELAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a8b1f-e061-46bd-886e-82c15ccdfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "elas_annual_merged = obs_elas_annual[['RGIId', 'Year', 'ELA_from_AAR_m']].merge(mod_elas_annual[['RGIId', 'Year', 'ELA_m']],\n",
    "                                                                                on=['RGIId', 'Year'])\n",
    "elas_annual_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bb9a5-a22f-41a1-9f5c-31f002300a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file name\n",
    "elas_annual_merged_fn = os.path.join(scm_path, 'analysis', 'ELAs_annual_mod_obs_merged.csv')\n",
    "if not os.path.exists(elas_annual_merged_fn):\n",
    "\n",
    "    # Merge modeled and remotely-sensed modeled ELAs\n",
    "    elas_annual_merged = obs_elas_annual[['RGIId', 'Year', 'ELA_from_AAR_m']].merge(mod_elas_annual[['RGIId', 'Year', 'ELA_m']],\n",
    "                                                                                    on=['RGIId', 'Year'])\n",
    "    \n",
    "    # Rename columns\n",
    "    elas_annual_merged.rename(columns={'ELA_from_AAR_m': 'ELA_obs_m', 'ELA_m': 'ELA_mod_m'}, inplace=True)\n",
    "    \n",
    "    # Remove 2023 values (no modeled data in 2023)\n",
    "    elas_annual_merged = elas_annual_merged.loc[elas_annual_merged['Year'] < 2023]\n",
    "        \n",
    "    # Calculate difference\n",
    "    elas_annual_merged['ELA_obs-mod_m'] = elas_annual_merged['ELA_obs_m'] - elas_annual_merged['ELA_mod_m']\n",
    "\n",
    "    # Save results\n",
    "    elas_annual_merged.to_csv(elas_annual_merged_fn, index=False)\n",
    "    print('Merged annual ELAs saved to file:', elas_annual_merged_fn)\n",
    "\n",
    "else:\n",
    "    elas_annual_merged = pd.read_csv(elas_annual_merged_fn)\n",
    "    print('Merged annual ELAs loaded.')\n",
    "    \n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(elas_annual_merged['ELA_obs-mod_m'], bins=50)\n",
    "ax.set_xlabel('ELA$_{obs}$ - ELA$_{mod}$ [m]')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('\\nDifference stats:')\n",
    "print(f'Mean diff = {np.nanmean((elas_annual_merged[\"ELA_obs_m\"] - elas_annual_merged[\"ELA_mod_m\"]).values)} m')\n",
    "print(f'Std. diff = {np.nanstd((elas_annual_merged[\"ELA_obs_m\"] - elas_annual_merged[\"ELA_mod_m\"]).values)} m')\n",
    "print(f'Median diff = {np.nanmedian((elas_annual_merged[\"ELA_obs_m\"] - elas_annual_merged[\"ELA_mod_m\"]).values)} m')\n",
    "print(f'MAD diff = {MAD((elas_annual_merged[\"ELA_obs_m\"] - elas_annual_merged[\"ELA_mod_m\"]).values, nan_policy=\"omit\")} m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c1a17-73bc-4c11-979b-5496087e5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rgi_id in slas_monthly_merged['RGIId'].drop_duplicates().values:\n",
    "    min_sla_obs = min_obs_sla.loc[min_obs_sla['RGIId']==rgi_id, 'SLA_min_m'].values[0]\n",
    "    min_sla_mod = mod_slas_monthly.loc[mod_slas_monthly['RGIId']==rgi_id, 'ELA_m'].min()\n",
    "    print(min_sla_obs, min_sla_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b936a9e-befa-434a-ab15-a3ef98b6d092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gscm-application",
   "language": "python",
   "name": "gscm-application"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
