{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mNQl_OJNtXf"
   },
   "source": [
    "# Load and save ERA5-Land Daily Aggregated data over an Area of Interest\n",
    "\n",
    "\n",
    "## Requirements: \n",
    "\n",
    "- __Google Earth Engine account__. Sign up [here](https://earthengine.google.com/signup/).\n",
    "- __GIS file__ of the Area of Interest (AOI) boundaries (.shp, .gpkg, or other file readable by geopandas). \n",
    "- __Digital Elevation Model__ (DEM) over the AOI (TIF, netCDF, or other file readable by xarray).\n",
    "    - If the DEM is referenced to the ellipsoid, comment out the lines below where ERA5-Land ellipsoid heights are reprojected to the geoid. \n",
    "    - A DEM from the ArcticDEM or NASADEM can be downloaded from Google Earth Engine using the AOI boundaries and [this Python function](https://github.com/RaineyAbe/glacier-snow-cover-mapping/blob/350af45c63fc77e6bd2f777fdc255d1d7d32c719/functions/pipeline_utils.py#L133) in the `glacier-snow-cover-mapping` repository. For the ArcticDEM, the function automatically saves a second DEM file reprojected to the geoid. \n",
    "- __ERA5-Land gridded geopotential__ file, used to calculate surface heights (TIF, netCDF, or other file readable by xarray).  Options for access:\n",
    "    - This code repository: \"geo_1279l4_0.1x0.1.grib2_v4_unpack.nc\" in the [`inputs-outputs` folder](https://github.com/RaineyAbe/snow-cover-mapping-application/tree/main/inputs-outputs). \n",
    "    - Download from the [ECMFW documentation for ERA5-Land](https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation#ERA5Land:datadocumentation-LandSurfaceModel) (see Table 1).\n",
    "- If your DEM is referenced to the geoid: __EGM96 geoid heights__, used to reproject ERA5-Land ellipsoid heights to the geoid (TIF, netCDF, or other file readable by xarray). Options for access:\n",
    "    - This code repository: \"us_nga_egm96_15.tif\" in the [`inputs-outputs` folder](https://github.com/RaineyAbe/snow-cover-mapping-application/tree/main/inputs-outputs). \n",
    "    - Download from the USA NGS via [Agisoft](https://www.agisoft.com/downloads/geoids/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KGjaZBrNuJc"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate and initialize Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-u8ICnmNx1q"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filters, etc. for ERA5-Land querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Date range for ERA5 querying\n",
    "date_start = '2023-10-01'\n",
    "date_end = '2023-12-01'\n",
    "\n",
    "# -----Bands to extract from ERA5-Land\n",
    "# See all data bands in the GEE documentation here: \n",
    "# https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_DAILY_AGGR#bands\n",
    "bands = ['temperature_2m', \n",
    "         'total_precipitation_sum', \n",
    "         'snowfall_sum', \n",
    "         'snowmelt_sum'] \n",
    "\n",
    "# -----Define lapse rate to apply to air temperatures\n",
    "lapse_rate = 6 # deg C / km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and calculate ERA5-Land ellipsoid heights, reproject to the geoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full path to geopotential for ERA5-Land\n",
    "era_geo_fn =  '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/inputs-outputs/geo_1279l4_0.1x0.1.grib2_v4_unpack.nc'\n",
    "\n",
    "# Full path to geoid heights\n",
    "egm96_fn = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/inputs-outputs/us_nga_egm96_15.tif'\n",
    "\n",
    "# Load ERA5-Land reference elevation data\n",
    "era_geo = xr.open_dataset(era_geo_fn)\n",
    "era_geo = era_geo / 9.8\n",
    "# shift longitudes > 180 to longitude - 360\n",
    "era_geo.longitude.data[era_geo.longitude.data > 180] = era_geo.longitude.data[era_geo.longitude.data>180] - 360\n",
    "\n",
    "# Load EGM96 geoid heights\n",
    "egm96 = xr.open_dataset(egm96_fn)\n",
    "# interpolate to era_geo coordinates\n",
    "egm96_interp = egm96.interp(x=era_geo.longitude, y=era_geo.latitude, method='nearest')\n",
    "\n",
    "# Subtract the geoid from ERA5-Land ellipsoid heights\n",
    "era_elevs_geoid = era_geo.z.data - egm96_interp.band_data.data\n",
    "era_geo['z'] = (('time', 'latitude', 'longitude'), era_elevs_geoid)\n",
    "era_geo = era_geo.rio.write_crs('EPSG:4326')\n",
    "\n",
    "# Plot geoid heights\n",
    "print(\"Note: Longitude degree values are incorrect \\nMatplotlib won't let me make the axis go from positive -> negative values\")\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(era_geo.z.data[0], extent=(0,360,-90,90), cmap='terrain')\n",
    "plt.title('Geoid heights calculated from ERA5-Land geopotential')\n",
    "plt.colorbar(label='meters', shrink=0.5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for grabbing data over the site area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to grab mean band values over the region of interest \n",
    "def calculate_band_means_over_area(image):\n",
    "    # Select specific bands\n",
    "    image = image.select(bands)\n",
    "    # Calculate mean for the selected bands in the AOI\n",
    "    mean_values = image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi_ee,\n",
    "        scale=1000)\n",
    "    return image.set(mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process multiple sites in the same folder with same file structure\n",
    "\n",
    "### Load names of sites to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study_sites_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/study-sites'\n",
    "rgi_ids = [x for x in sorted(os.listdir(study_sites_path)) if 'RGI' in x]\n",
    "\n",
    "# Filter to sites without ERA data\n",
    "rgi_ids = [x for x in rgi_ids if not len(glob.glob(os.path.join(study_sites_path, x, 'ERA', '*.csv'))) > 0]\n",
    "print(f'Sites to run = {len(rgi_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over sites and query GEE for ERA5-Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Iterate over sites\n",
    "for rgi_id in tqdm(rgi_ids):\n",
    "\n",
    "    # Define path to ERA data\n",
    "    era_path = os.path.join(study_sites_path, rgi_id, 'ERA')\n",
    "\n",
    "    # Make output directory if it does not exist\n",
    "    if not os.path.exists(era_path):\n",
    "        os.mkdir(era_path)\n",
    "        # print('Made directory for output ERA files')\n",
    "    \n",
    "    # Check if ERA5-Land data already exist in directory\n",
    "    out_fn = os.path.join(era_path, rgi_id + '_ERA5-Land_' + date_start + '_' + date_end + '.csv')\n",
    "    if not os.path.exists(out_fn):\n",
    "\n",
    "        # Load AOI and DEM\n",
    "        aoi_fn = os.path.join(study_sites_path, rgi_id, 'AOIs', rgi_id + '_outline.shp')\n",
    "        try:\n",
    "            aoi = gpd.read_file(aoi_fn)\n",
    "            \n",
    "            aoi = aoi.to_crs('EPSG:4326')\n",
    "            dem_fns = glob.glob(os.path.join(study_sites_path, rgi_id, 'DEMs', '*.tif'))\n",
    "            if any(['ArcticDEM' in x for x in dem_fns]):\n",
    "                dem_fn = [x for x in dem_fns if '_geoid.tif' in x][0]\n",
    "            elif any (['USGS' in x for x in dem_fns]):\n",
    "                dem_fn = [x for x in dem_fns if '_geoid.tif' in x][0]\n",
    "            else:\n",
    "                dem_fn = glob.glob(os.path.join(study_sites_path, rgi_id, 'DEMs', rgi_id + '*NASADEM*.tif'))[0]\n",
    "            dem = xr.open_dataset(dem_fn)\n",
    "            dem = dem.rio.reproject('EPSG:4326') # reproject to WGS84\n",
    "            dem = xr.where((dem > 1e38) or (dem<=-9999), np.nan, dem) # remove no data values\n",
    "            dem = dem.rio.write_crs('EPSG:4326')\n",
    "            \n",
    "            # Reformat for GEE querying\n",
    "            aoi = gpd.read_file(aoi_fn)\n",
    "            # reproject to WGS84\n",
    "            aoi_wgs = aoi.to_crs('EPSG:4326')\n",
    "            # Reformat AOI to ee.Geometry.Polygon \n",
    "            region = ee.Geometry.Polygon(list(zip(aoi_wgs.geometry[0].exterior.coords.xy[0],\n",
    "                                                  aoi_wgs.geometry[0].exterior.coords.xy[1])))\n",
    "    \n",
    "            # Grab median elevation over the AOI\n",
    "            if 'Zmed' in list(aoi.columns): # If using an RGI outline, use the \"Zmed\" value\n",
    "                zmed = aoi['Zmed'].values[0]\n",
    "            else: # Otherwise, use the median value from the DEM\n",
    "                zmed = np.nanmedian(dem.data)\n",
    "            # print(f'Median site elevation = {np.round(zmed, 2)} m')\n",
    "    \n",
    "            # Grab median ERA5-Land elevation over AOI\n",
    "            # interpolate to DEM coordinates\n",
    "            era_geo_interp = era_geo.interp(longitude=dem.x, latitude=dem.y, method='linear')\n",
    "            # clip to AOI\n",
    "            era_geo_interp_clip = era_geo_interp.rio.clip(aoi_wgs.geometry)\n",
    "            # calculate median elevation\n",
    "            elev_med_era = np.nanmedian(np.ravel(era_geo_interp_clip.z.data[0]))\n",
    "            # print(f'Median site elevation from ERA5-Land = {np.round(elev_med_era, 2)} m')\n",
    "            \n",
    "            # Query GEE for the ERA5-Land dataset\n",
    "            era5_land = (ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n",
    "                         .filter(ee.Filter.date(date_start, date_end))\n",
    "                         .filterBounds(region))\n",
    "        \n",
    "            # Calculate mean daily values for all bands\n",
    "            era5_land_mean = era5_land.map(calculate_band_means_over_area)\n",
    "            \n",
    "            # Compile statistics into a pandas.DataFrame\n",
    "            # ceate empty lists to store the data\n",
    "            dates = []\n",
    "            mean_values_list = {band: [] for band in bands}\n",
    "            # iterate over the ImageCollection to collect data\n",
    "            for image in era5_land_mean.getInfo()['features']:\n",
    "                date = pd.to_datetime(image['properties']['system:time_start'], unit='ms')  # Convert to datetime\n",
    "                dates.append(date)\n",
    "                mean_values = image['properties']\n",
    "                for band in bands:\n",
    "                    mean_values_list[band].append(mean_values[band])\n",
    "            # create a Pandas DataFrame\n",
    "            data = {'Date': dates}\n",
    "            data.update(mean_values_list)\n",
    "            df = pd.DataFrame(data)\n",
    "    \n",
    "            # Adjust air temperatures for elevation using defined lapse rate\n",
    "            if 'temperature_2m' in list(df.columns):\n",
    "                # Convert air temperatures to Celsius (from Kelvin)\n",
    "                df['temperature_2m_C'] = df['temperature_2m'] - 273.15\n",
    "                # Adjust air temperatures using reference elevations and lapse rate\n",
    "                df['temperature_2m_C_adjusted'] = df['temperature_2m_C'] - lapse_rate * (zmed - elev_med_era)/1e3\n",
    "            \n",
    "                # Add cumulative positive degree days\n",
    "                # Calculate Positive Degree Days (PDDs)\n",
    "                df['positive_degree_days'] = df['temperature_2m_C_adjusted'].apply(lambda x: max(0, x))\n",
    "                # Calculate cumulative sum and reset at the start of each calendar year\n",
    "                df['cumulative_positive_degree_days'] = df.groupby(df['Date'].dt.year, group_keys=True)['positive_degree_days'].cumsum()\n",
    "                # Reset cumulative sum to zero at the start of each year\n",
    "                df['cumulative_positive_degree_days'] = df.groupby(df['Date'].dt.year, group_keys=False)['cumulative_positive_degree_days'].apply(lambda x: x - x.iloc[0])\n",
    "            \n",
    "            # Add cumulative annual precipitation, snowfall, and snowmelt\n",
    "            # Restart the count each water year \n",
    "            df['water_year'] = df['Date'].apply(lambda x: x.year if x.month >= 10 else x.year - 1) # add a water year column\n",
    "            if 'total_precipitation_sum' in list(df.columns):\n",
    "                df['cumluative_total_precipitation_sum'] = df.groupby('water_year')['total_precipitation_sum'].cumsum()    \n",
    "            if 'snowfall_sum' in list(df.columns):\n",
    "                df['cumluative_snowfall_sum'] = df.groupby('water_year')['snowfall_sum'].cumsum()   \n",
    "            if 'snowmelt_sum' in list(df.columns):\n",
    "                df['cumulative_snowmelt_sum'] = df.groupby('water_year')['snowmelt_sum'].cumsum()\n",
    "    \n",
    "            # Save DataFrame to CSV\n",
    "            df.to_csv(out_fn, index=False)\n",
    "            # print('ERA5-Land data variables saved to file:', out_fn)\n",
    "            \n",
    "            # Plot data variables\n",
    "            plot_vars = [x for x in list(df.columns) if (x!='Date') & (x!='water_year')]\n",
    "            plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "            \n",
    "            fig, ax = plt.subplots(len(plot_vars), 1, figsize=(8, 4*len(plot_vars)))\n",
    "            for i, var in enumerate(plot_vars):\n",
    "                ax[i].plot(df.Date.values.astype('datetime64[ns]'), df[var].values, '.', markersize=3)\n",
    "                ax[i].set_title(var)\n",
    "                ax[i].grid()\n",
    "            plt.close()\n",
    "        \n",
    "            # Save figure\n",
    "            fig_fn = out_fn.replace('.csv', '.png')\n",
    "            fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "            # print('Figure saved to file: ', fig_fn)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(rgi_id)\n",
    "            print(e, '\\n')\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a single site\n",
    "\n",
    "### Define paths in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlEQRqPICO24"
   },
   "outputs": [],
   "source": [
    "# Define name of study site, used in output file names\n",
    "site_name = 'Hubbard'\n",
    "\n",
    "# Full path to AOI boundaries \n",
    "aoi_fn = '/Users/raineyaberle/Research/Hubbard/velocity/center.gpkg'\n",
    "\n",
    "# Full path to DEM\n",
    "dem_fn = '/Users/raineyaberle/Research/Hubbard/DEMs/ifsar_hubbardDEM.tif'\n",
    "\n",
    "# Full path to geopotential for ERA5-Land\n",
    "era_geo_fn =  '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/inputs-outputs/geo_1279l4_0.1x0.1.grib2_v4_unpack.nc'\n",
    "\n",
    "# Full path to geoid heights\n",
    "egm96_fn = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/inputs-outputs/us_nga_egm96_15.tif'\n",
    "\n",
    "# Path where output files will be saved\n",
    "out_path = '/Users/raineyaberle/Research/Hubbard/weather/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query GEE for ERA5-Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load AOI\n",
    "aoi = gpd.read_file(aoi_fn)\n",
    "# reproject to WGS84\n",
    "aoi_wgs = aoi.to_crs('EPSG:4326')\n",
    "\n",
    "# -----Load DEM\n",
    "dem = rxr.open_rasterio(dem_fn)\n",
    "# reproject to WGS84\n",
    "dem = dem.rio.reproject('EPSG:4326')\n",
    "# remove no data values\n",
    "dem = xr.where((dem > 1e38) | (dem<=-9999), np.nan, dem)\n",
    "dem = dem.rio.write_crs('EPSG:4326')\n",
    "    \n",
    "# -----Grab median elevation over the AOI\n",
    "if 'Zmed' in list(aoi.columns): # If using an RGI outline, use the \"Zmed\" value\n",
    "    zmed = float(aoi['Zmed'].values[0])\n",
    "else: # Otherwise, use the median value from the DEM\n",
    "    zmed = np.nanmedian(dem.data)\n",
    "print(f'Median site elevation from DEM = {np.round(zmed, 2)} m')\n",
    "\n",
    "# -----Query GEE for ERA5-Land\n",
    "# Make output directory if it does not exist\n",
    "if not os.path.exists(era_path):\n",
    "    os.mkdir(era_path)\n",
    "    # print('Made directory for output ERA files')\n",
    "\n",
    "# Check if ERA5-Land data already exist in directory\n",
    "out_fn = os.path.join(era_path, rgi_id + '_ERA5-Land_' + date_start + '_' + date_end + '.csv')\n",
    "if not os.path.exists(out_fn):\n",
    "            \n",
    "    # Reformat AOI to ee.Geometry.Polygon \n",
    "    region = ee.Geometry.Polygon(list(zip(aoi_wgs.geometry[0].exterior.coords.xy[0],\n",
    "                                          aoi_wgs.geometry[0].exterior.coords.xy[1])))\n",
    "    \n",
    "    # Query GEE for the ERA5-Land dataset\n",
    "    era5_land = (ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n",
    "                 .filter(ee.Filter.date(date_start, date_end))\n",
    "                 .filterBounds(region))\n",
    "\n",
    "    # Calculate mean daily values for all bands\n",
    "    era5_land_mean = era5_land.map(calculate_band_means_over_area)\n",
    "            \n",
    "    # Compile statistics into a pandas.DataFrame\n",
    "    # ceate empty lists to store the data\n",
    "    dates = []\n",
    "    mean_values_list = {band: [] for band in bands}\n",
    "    # iterate over the ImageCollection to collect data\n",
    "    for image in era5_land_mean.getInfo()['features']:\n",
    "        date = pd.to_datetime(image['properties']['system:time_start'], unit='ms')  # Convert to datetime\n",
    "        dates.append(date)\n",
    "        mean_values = image['properties']\n",
    "        for band in bands:\n",
    "            mean_values_list[band].append(mean_values[band])\n",
    "    # create a Pandas DataFrame\n",
    "    data = {'Date': dates}\n",
    "    data.update(mean_values_list)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Adjust air temperatures for elevation using defined lapse rate\n",
    "    if 'temperature_2m' in list(df.columns):\n",
    "        # Convert air temperatures to Celsius (from Kelvin)\n",
    "        df['temperature_2m_C'] = df['temperature_2m'] - 273.15\n",
    "        # Adjust air temperatures using reference elevations and lapse rate\n",
    "        df['temperature_2m_C_adjusted'] = df['temperature_2m_C'] - lapse_rate * (zmed - elev_med_era)/1e3\n",
    "    \n",
    "        # Add cumulative positive degree days\n",
    "        # Calculate Positive Degree Days (PDDs)\n",
    "        df['positive_degree_days'] = df['temperature_2m_C_adjusted'].apply(lambda x: max(0, x))\n",
    "        # Calculate cumulative sum and reset at the start of each calendar year\n",
    "        df['cumulative_positive_degree_days'] = df.groupby(df['Date'].dt.year, group_keys=True)['positive_degree_days'].cumsum()\n",
    "        # Reset cumulative sum to zero at the start of each year\n",
    "        df['cumulative_positive_degree_days'] = df.groupby(df['Date'].dt.year, group_keys=False)['cumulative_positive_degree_days'].apply(lambda x: x - x.iloc[0])\n",
    "    \n",
    "    # Add cumulative annual precipitation, snowfall, and snowmelt\n",
    "    # Restart the count each water year \n",
    "    df['water_year'] = df['Date'].apply(lambda x: x.year if x.month >= 10 else x.year - 1) # add a water year column\n",
    "    if 'total_precipitation_sum' in list(df.columns):\n",
    "        df['cumluative_total_precipitation_sum'] = df.groupby('water_year')['total_precipitation_sum'].cumsum()    \n",
    "    if 'snowfall_sum' in list(df.columns):\n",
    "        df['cumluative_snowfall_sum'] = df.groupby('water_year')['snowfall_sum'].cumsum()   \n",
    "    if 'snowmelt_sum' in list(df.columns):\n",
    "        df['cumulative_snowmelt_sum'] = df.groupby('water_year')['snowmelt_sum'].cumsum()\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(out_fn, index=False)\n",
    "    # print('ERA5-Land data variables saved to file:', out_fn)\n",
    "    \n",
    "    # Plot data variables\n",
    "    plot_vars = [x for x in list(df.columns) if (x!='Date') & (x!='water_year')]\n",
    "    plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "    \n",
    "    fig, ax = plt.subplots(len(plot_vars), 1, figsize=(8, 4*len(plot_vars)))\n",
    "    for i, var in enumerate(plot_vars):\n",
    "        ax[i].plot(df.Date.values.astype('datetime64[ns]'), df[var].values, '.', markersize=3)\n",
    "        ax[i].set_title(var)\n",
    "        ax[i].grid()\n",
    "    plt.close()\n",
    "\n",
    "    # Save figure\n",
    "    fig_fn = out_fn.replace('.csv', '.png')\n",
    "    fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "    print('Figure saved to file: ', fig_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPUSxvA9DdKOQi56SFRph5u",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
