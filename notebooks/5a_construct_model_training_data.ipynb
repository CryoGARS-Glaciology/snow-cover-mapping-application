{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4611ae9a-ec63-497a-a099-8703aed0bc4f",
   "metadata": {},
   "source": [
    "# Construct training data for model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a3246b-95e1-4962-a8ef-8de5612d0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot\n",
    "import sys\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f026f-6977-49ca-bcff-8ed06aaa72f9",
   "metadata": {},
   "source": [
    "## Define paths in directory, import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c2a0c-4669-4dad-a5ce-9ff1402fdf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/'\n",
    "sys.path.append(os.path.join(base_path, 'functions'))\n",
    "import model_analyze_utils as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be47bba-54aa-44e0-8055-b452ed08ee3f",
   "metadata": {},
   "source": [
    "## Load RGI glacier boundaries, ERA time series, and snowline time series for all sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8004b-ed3c-4f07-a7b5-688d250eda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load RGI glacier boundaries (AOIs)\n",
    "aois_fn = 'all_aois.shp'\n",
    "aois = gpd.read_file(os.path.join(scm_path, 'all_AOIs', aois_fn))\n",
    "aois[['O1Region', 'O2Region']] = aois[['O1Region', 'O2Region']].astype(int)\n",
    "print('All AOIs loaded from file')\n",
    "\n",
    "# -----Load ERA data\n",
    "eras_fn = 'all_era_data.csv'\n",
    "eras = pd.read_csv(os.path.join(scm_path, 'all_ERA_data', eras_fn))\n",
    "eras['Date'] = pd.to_datetime(eras['Date'], format='mixed')\n",
    "print('All ERA data loaded from file')\n",
    "    \n",
    "# -----Load all snowlines\n",
    "snowlines_fn = 'all_snowlines.csv'\n",
    "snowlines = pd.read_csv(os.path.join(scm_path, 'all_snowlines', snowlines_fn))\n",
    "snowlines['datetime'] = pd.to_datetime(snowlines['datetime'], format='mixed')\n",
    "print('All snowlines loaded from file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae67c0-4adf-42a5-8176-e01462489eb3",
   "metadata": {},
   "source": [
    "## Add Hypsometric Index and Subregion columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e237cd-0625-4256-9d5a-d2f1261a580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define some functions\n",
    "# Adjust DEM data variables\n",
    "def adjust_data_vars(dem_xr):\n",
    "    if 'band_data' in dem_xr.data_vars:\n",
    "        dem_xr = dem_xr.rename({'band_data': 'elevation'})\n",
    "    if 'band' in dem_xr.dims:\n",
    "        elev_data = dem_xr.elevation.data[0]\n",
    "        dem_xr = dem_xr.drop_dims('band')\n",
    "        dem_xr['elevation'] = (('y', 'x'), elev_data)\n",
    "    return dem_xr\n",
    "\n",
    "# Calculate Hypsometric Index (HI)\n",
    "# Jiskoot et al. (2009): https://doi.org/10.3189/172756410790595796\n",
    "def calculate_hypsometric_index(dem_fn, aoi):\n",
    "    # load DEM as DataArray\n",
    "    dem = rxr.open_rasterio(dem_fn)\n",
    "    # reproject DEM to AOI CRS\n",
    "    dem = dem.rio.reproject('EPSG:'+str(aoi.crs.to_epsg()))\n",
    "    # clip DEM to AOI\n",
    "    dem_aoi = dem.rio.clip(aoi.geometry, aoi.crs)\n",
    "    # convert to dataset\n",
    "    dem_aoi_ds = dem_aoi.to_dataset(name='elevation')\n",
    "    # adjust DEM data variables\n",
    "    dem_aoi_ds = adjust_data_vars(dem_aoi_ds)\n",
    "    # set no data values to NaN\n",
    "    dem_aoi_ds = xr.where((dem_aoi_ds > 1e38) | (dem_aoi_ds <= -9999), np.nan, dem_aoi_ds)\n",
    "    # calculate elevation statistics\n",
    "    h_max = np.nanmax(np.ravel(dem_aoi_ds.elevation.data))\n",
    "    h_min = np.nanmin(np.ravel(dem_aoi_ds.elevation.data))\n",
    "    h_med = np.nanmedian(np.ravel(dem_aoi_ds.elevation.data))\n",
    "    # calculate HI, where HI = (H_max - H_med) / (H_med - H_min). If 0 < HI < 1, HI = -1/HI.\n",
    "    hi = (h_max - h_med) / (h_med - h_min)\n",
    "    if (0 < hi) and (hi < 1):\n",
    "        hi = -1 / hi\n",
    "    # determine HI category\n",
    "    if hi <= -1.5:\n",
    "        hi_category = 'Very top heavy'\n",
    "    elif (hi > -1.5) and (hi <= -1.2):\n",
    "        hi_category = 'Top heavy'\n",
    "    elif (hi > -1.2) and (hi <= 1.2):\n",
    "        hi_category = 'Equidimensional'\n",
    "    elif (hi > 1.2) and (hi <= 1.5):\n",
    "        hi_category = 'Bottom heavy'\n",
    "    elif hi > 1.5:\n",
    "        hi_category = 'Very bottom heavy'\n",
    "\n",
    "    return hi, hi_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d455bb-187b-433e-bb14-a3e519bd3420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Define columns to save in training data for each dataset\n",
    "aoi_columns = ['O1Region', 'O2Region', 'Subregion', 'Area', 'Zmed', 'Slope', 'Aspect', 'Lmax', 'TermType', 'Surging']\n",
    "era_columns = ['Date', 'Cumulative_Precipitation_mwe', 'Cumulative_Snowfall_mwe', \n",
    "               'Cumulative_Snowmelt_mwe', 'Positive_Degree_Days', 'Cumulative_Positive_Degree_Days']\n",
    "snowlines_columns = ['Date', 'site_name', 'snowline_elevs_median_m', 'SCA_m2', 'AAR', 'ELA_from_AAR_m']\n",
    "\n",
    "# -----Initialize full training data frame\n",
    "training_data = pd.DataFrame()\n",
    "\n",
    "# -----Iterate over site names\n",
    "for site_name in tqdm(aois['RGIId'].drop_duplicates().values):\n",
    "    \n",
    "    # subset AOIs\n",
    "    aoi = aois.loc[aois['RGIId']==site_name]\n",
    "\n",
    "    # subset snowlines\n",
    "    snowlines_site = snowlines.loc[snowlines['site_name']==site_name]\n",
    "    # add date column\n",
    "    snowlines_site.loc[:, 'Date'] = snowlines_site['datetime'].values.astype('datetime64[D]')\n",
    "    # subset columns\n",
    "    snowlines_site = snowlines_site[snowlines_columns]\n",
    "    \n",
    "    # subset ERA data\n",
    "    eras_site = eras.loc[eras['site_name']==site_name]\n",
    "\n",
    "    # Merge snowlines and ERA time series\n",
    "    training_data_site = snowlines_site.merge(eras_site, how='left', on='Date')\n",
    "    # Identify subregion name\n",
    "    o1, o2 = aoi[['O1Region', 'O2Region']].values[0].astype(int)\n",
    "\n",
    "    # Add AOI columns to merged snowlines and ERA dataframe\n",
    "    subregion, color = f.determine_subregion_name_color(o1, o2)\n",
    "    aoi.loc[:, 'Subregion'] = subregion\n",
    "    for aoi_column in aoi_columns:\n",
    "        training_data_site[aoi_column] = aoi[aoi_column].values[0]\n",
    "    \n",
    "    # determine DEM file name\n",
    "    dem_fns = glob.glob(os.path.join(scm_path, 'study-sites', site_name, 'DEMs', site_name + '*.tif'))\n",
    "    if len(dem_fns) < 1:\n",
    "        continue\n",
    "    if ('ArcticDEM' in dem_fns[0]) | ('USGS' in dem_fns[0]):\n",
    "        dem_fn = [x for x in dem_fns if '_geoid.tif' in x][0]\n",
    "    else:\n",
    "        dem_fn = dem_fns[0]\n",
    "\n",
    "    # calculate hyspometric index using DEM and AOI\n",
    "    hi, hi_category = calculate_hypsometric_index(dem_fn, aoi)\n",
    "    \n",
    "    # add to training data table\n",
    "    training_data_site['Hypsometric_Index'] = hi\n",
    "    training_data_site['Hypsometric_Index_Category'] = hi_category\n",
    "\n",
    "    # Concatenate site training data to full training data dataframe\n",
    "    training_data = pd.concat([training_data, training_data_site])\n",
    "    \n",
    "training_data.rename(columns={'site_name_x': 'site_name'})\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ad40f-8018-4df9-8494-284638c0283b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
