{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8440394-6f37-4aec-a623-f1cd0c7e908d",
   "metadata": {},
   "source": [
    "# Fit linear trendline to AARs, PDDs, and snowfall for all sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284a7b5-8635-4e3f-971e-17cbd235b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import iqr\n",
    "# Suppress warnings to prevent kernel crashing (future warning from pandas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04adc2af-5496-415d-9138-68664f71c590",
   "metadata": {},
   "source": [
    "## Define paths in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e5fa5-1c99-4707-9d90-dc0f2bceb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/'\n",
    "sys.path.append(os.path.join(base_path, 'functions'))\n",
    "import model_analyze_utils as f\n",
    "\n",
    "# scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "scm_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "figures_out_path = os.path.join(base_path, 'figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733ea5f-506f-40f4-82d3-876427738009",
   "metadata": {},
   "source": [
    "## Load compiled glacier boundaries and snowlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748974c3-8627-4b76-a5ea-afff7c5ed7cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Load glacier boundaries with climate clusters\n",
    "aois_fn = os.path.join(scm_path, 'compiled_data', 'all_aois_climate_cluster.shp')\n",
    "aois = gpd.read_file(aois_fn)\n",
    "aois[['O1Region', 'O2Region']] = aois[['O1Region', 'O2Region']].astype(int)\n",
    "print('All AOIs with climate clusters loaded from file.')\n",
    "\n",
    "# -----Load ERA data\n",
    "eras_fn = os.path.join(scm_path, 'compiled_data', 'all_era_data.csv')\n",
    "eras = pd.read_csv(eras_fn)\n",
    "# format dates as datetimes\n",
    "eras['Date'] = pd.to_datetime(eras['Date'])\n",
    "print('All ERA data loaded from file.')\n",
    "\n",
    "# -----Load and compile snowlines\n",
    "snowlines_fn = os.path.join(scm_path, 'compiled_data', 'all_snowlines.csv')\n",
    "snowlines = pd.read_csv(snowlines_fn)\n",
    "snowlines['datetime'] = pd.to_datetime(snowlines['datetime'], format='mixed')\n",
    "print('All snowlines loaded from file.')\n",
    "# snowlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f42c5-2e36-49a0-952b-b7f7aa86b7dc",
   "metadata": {},
   "source": [
    "## Filter snowlines to before September, merge snowlines and ERA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f48cc1-9a25-4f44-8d99-214b431bb3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add Month column to snowlines\n",
    "snowlines['Month'] = pd.DatetimeIndex(snowlines['datetime']).month.values\n",
    "eras['Month'] = pd.DatetimeIndex(eras['Date']).month.values\n",
    "# Remove observations after August\n",
    "snowlines = snowlines.loc[snowlines['Month'] <= 8]\n",
    "eras = eras.loc[eras['Month'] <= 8]\n",
    "# Unify date columns for merging\n",
    "snowlines['Date'] = snowlines['datetime'].values.astype('datetime64[D]')\n",
    "eras['Date'] = eras['Date'].values.astype('datetime64[D]')\n",
    "# Merge on site name and dates\n",
    "merged = pd.merge(snowlines, eras, on=['site_name', 'Date'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a0096-dc11-433f-90da-7f0b74d6e217",
   "metadata": {},
   "source": [
    "## Add climate cluster column to merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26e164-5d57-45d5-9818-a69a614c7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[['cluster', 'clustName']] = '', ''\n",
    "for cluster in aois['cluster'].drop_duplicates().values:\n",
    "    aois_cluster = aois.loc[aois['cluster']==cluster]\n",
    "    site_names = aois_cluster['RGIId'].drop_duplicates().values\n",
    "    merged.loc[merged['site_name'].isin(site_names), 'cluster'] = cluster\n",
    "    merged.loc[merged['site_name'].isin(site_names), 'clustName'] = aois_cluster['clustName'].values[0]\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b699b-6118-4fed-bc5c-061ad9205cf0",
   "metadata": {},
   "source": [
    "## Fit linear and non-parametric models to PDDs and Snowfall vs. AARs for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5652a-7b2b-43d2-b68d-df2e421d85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define non-parametric fit function\n",
    "def svr_fit(X, y):    \n",
    "    model = SVR().fit(X, y)\n",
    "    score = model.score(X, y)\n",
    "    return model, score\n",
    "\n",
    "# Define linear fit function\n",
    "def linear_fit(X, y):\n",
    "    model = LinearRegression().fit(X,y)\n",
    "    score = model.score(X, y)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacacc71-11df-44b0-9dfb-966d06e04a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize dataframe for storing results\n",
    "fit_clusters_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over subregions \n",
    "for cluster in tqdm(merged['cluster'].drop_duplicates().values):\n",
    "    # Subset merged data to subregion\n",
    "    merged_cluster = merged.loc[merged['cluster']==cluster]\n",
    "    # Grab cluster name \n",
    "    cluster_name = merged_cluster['clustName'].values[0]\n",
    "    # Fit linear and SVR models to data\n",
    "    X = merged_cluster[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values\n",
    "    y = merged_cluster['AAR'].values\n",
    "    if (np.ravel(X)=='').all():\n",
    "        model_linear, score_linear = np.nan, np.nan\n",
    "        model_svr, score_svr = np.nan, np.nan\n",
    "    else:\n",
    "        model_linear, score_linear = linear_fit(X, y)\n",
    "        model_svr, score_svr = svr_fit(X, y)\n",
    "        # plot\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.plot(X[:,0], y, '.')\n",
    "        plt.plot(X[:,0], model_linear.predict(X), '.b', label='Linear')\n",
    "        plt.plot(X[:,0], model_svr.predict(X), '.m', label='SVR')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlabel('$\\Sigma$PDDs')\n",
    "        plt.ylabel('AAR')\n",
    "        plt.ylim(0,1)\n",
    "        plt.title(cluster_name \n",
    "                  + '\\nLinear score = ' + str(np.round(score_linear, 4)) \n",
    "                  + '\\nSVR score = ' + str(np.round(score_svr, 4)))\n",
    "        plt.show()\n",
    "    # Save in dataframe\n",
    "    df = pd.DataFrame({'cluster': [cluster],\n",
    "                       'clustName': [cluster_name],\n",
    "                       'coef_linear': [model_linear.coef_[0]],\n",
    "                       'intercept_linear': [model_linear.intercept_],\n",
    "                       'score_linear': [score_linear],\n",
    "                       'N': [len(y)]})\n",
    "    # Concatenate to full dataframe\n",
    "    fit_clusters_df = pd.concat([fit_clusters_df, df])\n",
    "\n",
    "# Sort by cluster\n",
    "fit_clusters_df.sort_values(by='cluster', inplace=True)\n",
    "    \n",
    "# Save to file\n",
    "fit_clusters_fn = os.path.join(scm_path, 'results', 'aar_pdd_snowfall_linear_fit_clusters.csv')\n",
    "fit_clusters_df.to_csv(fit_clusters_fn, index=False)\n",
    "print('Data table saved to file:', fit_clusters_fn)\n",
    "fit_clusters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0aafad-a4fd-460a-93c1-95a28f82eb8a",
   "metadata": {},
   "source": [
    "## Fit a linear trend to PDDs and Snowfall vs. AARs for each site separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c1180-f410-479d-b03e-21c7612987b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Suppress warnings to prevent kernel crashing (future warning from pandas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize results dataframe\n",
    "fit_sites_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over site names\n",
    "for site_name in tqdm(merged['site_name'].drop_duplicates().values):\n",
    "    # Subset data\n",
    "    merged_site = merged.loc[merged['site_name']==site_name]\n",
    "    # Grab O1 and O2 regions\n",
    "    o1 = aois.loc[aois['RGIId']==site_name, 'O1Region'].values[0]\n",
    "    o2 = aois.loc[aois['RGIId']==site_name, 'O2Region'].values[0]\n",
    "    # Grab cluster and cluster name\n",
    "    cluster, cluster_name = merged_site['cluster'].values[0], merged_site['clustName'].values[0]\n",
    "    # Fit linear trendline to AAR and Cumulative PDDs\n",
    "    X = merged_site[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values.reshape(-1, 2)\n",
    "    y = merged_site['AAR']\n",
    "    if (np.ravel(X)=='').all():\n",
    "        model_linear, score_linear = np.nan, np.nan\n",
    "        print('none')\n",
    "    else:\n",
    "        model_linear, score_linear = linear_fit(X, y)\n",
    "    # Save in dataframe\n",
    "    df = pd.DataFrame({'site_name': [site_name],\n",
    "                       'O1Region': [o1],\n",
    "                       'O2Region': [o2],\n",
    "                       'cluster': [cluster],\n",
    "                       'clustName': [cluster_name],\n",
    "                       'coef_linear': [model_linear.coef_[0]],\n",
    "                       'intercept_linear': [model_linear.intercept_],\n",
    "                       'score_linear': [score_linear],\n",
    "                       'N': [len(y)]})\n",
    "    # Concatenate to full dataframe\n",
    "    fit_sites_df = pd.concat([fit_sites_df, df])\n",
    "\n",
    "# Save to file\n",
    "fit_sites_fn = os.path.join(scm_path, 'results', 'aar_pdd_snowfall_linear_fit_sites.csv')\n",
    "fit_sites_df.to_csv(fit_sites_fn, index=False)\n",
    "print('Data table saved to file:', fit_sites_fn)\n",
    "fit_sites_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4969c18-8088-4c22-8da8-ac078095a522",
   "metadata": {},
   "source": [
    "## Fit a linear trend to max. PDDs and max. Snowfall vs. min. AARs for each subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05688685-1e8f-40cf-a9e4-d4cb680dd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings to prevent kernel crashing (future warning from pandas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize results dataframe\n",
    "fit_subregion_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over site names\n",
    "for o1, o2 in tqdm(aois[['O1Region', 'O2Region']].drop_duplicates().values):\n",
    "    # Grab subregion name\n",
    "    subregion_name, color = f.determine_subregion_name_color(o1, o2)\n",
    "    print(subregion_name)\n",
    "    # Grab site names\n",
    "    site_names = aois.loc[(aois['O1Region']==o1) & (aois['O2Region']==o2), 'RGIId'].values\n",
    "    # Subset data to subregion\n",
    "    merged_subregion = merged.loc[merged['site_name'].isin(site_names)]\n",
    "    # Fit linear trendline to AAR and Cumulative PDDs\n",
    "    X = merged_subregion[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values.reshape(-1, 2)\n",
    "    y = merged_subregion['AAR']\n",
    "    if (np.ravel(X)=='').all():\n",
    "        model_linear, score_linear = np.nan, np.nan\n",
    "        print('none')\n",
    "    else:\n",
    "        model_linear, score_linear = linear_fit(X, y)\n",
    "        # plot\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.plot(X[:,0], y, '.')\n",
    "        plt.plot(X[:,0], model_linear.predict(X), '.m', label='Linear')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlabel('$\\Sigma$PDDs')\n",
    "        plt.ylabel('AAR')\n",
    "        plt.ylim(0,1)\n",
    "        plt.title(subregion_name \n",
    "                  + '\\nLinear score = ' + str(np.round(score_linear, 4)))\n",
    "        plt.show()\n",
    "    # Save in dataframe\n",
    "    df = pd.DataFrame({'Subregion': [subregion_name],\n",
    "                       'O1Region': [o1],\n",
    "                       'O2Region': [o2],\n",
    "                       'coef_linear': [model_linear.coef_[0]],\n",
    "                       'intercept_linear': [model_linear.intercept_],\n",
    "                       'score_linear': [score_linear],\n",
    "                       'N': [len(y)]})\n",
    "    # Concatenate to full dataframe\n",
    "    fit_subregion_df = pd.concat([fit_subregion_df, df])\n",
    "\n",
    "# Save to file\n",
    "fit_subregion_fn = os.path.join(scm_path, 'results', 'aar_pdd_snowfall_linear_fit_subregions.csv')\n",
    "fit_subregion_df.to_csv(fit_subregion_fn, index=False)\n",
    "print('Data table saved to file:', fit_subregion_fn)\n",
    "fit_subregion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c104c-521e-413f-bb32-1f0cd5233575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
