{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8440394-6f37-4aec-a623-f1cd0c7e908d",
   "metadata": {},
   "source": [
    "# Fit linear trendline to AARs, PDDs, and snowfall for all sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284a7b5-8635-4e3f-971e-17cbd235b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "# Suppress warnings to prevent kernel crashing (future warning from pandas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04adc2af-5496-415d-9138-68664f71c590",
   "metadata": {},
   "source": [
    "## Define paths in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e5fa5-1c99-4707-9d90-dc0f2bceb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/'\n",
    "sys.path.append(os.path.join(base_path, 'functions'))\n",
    "import model_analyze_utils as f\n",
    "\n",
    "# scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "scm_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "figures_out_path = os.path.join(base_path, 'figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733ea5f-506f-40f4-82d3-876427738009",
   "metadata": {},
   "source": [
    "## Load compiled glacier boundaries and snowlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748974c3-8627-4b76-a5ea-afff7c5ed7cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Load glacier boundaries with climate clusters\n",
    "aois_fn = os.path.join(scm_path, 'compiled_data', 'all_aois_climate_cluster.shp')\n",
    "aois = gpd.read_file(aois_fn)\n",
    "aois[['O1Region', 'O2Region']] = aois[['O1Region', 'O2Region']].astype(int)\n",
    "print('All AOIs with climate clusters loaded from file.')\n",
    "\n",
    "# -----Load ERA data\n",
    "eras_fn = os.path.join(scm_path, 'compiled_data', 'all_era_data.csv')\n",
    "eras = pd.read_csv(eras_fn)\n",
    "# format dates as datetimes\n",
    "eras['Date'] = pd.to_datetime(eras['Date'])\n",
    "print('All ERA data loaded from file.')\n",
    "\n",
    "# -----Load compiled snowlines\n",
    "snowlines_fn = os.path.join(scm_path, 'compiled_data', 'all_snowlines.csv')\n",
    "snowlines = pd.read_csv(snowlines_fn)\n",
    "snowlines['datetime'] = pd.to_datetime(snowlines['datetime'], format='mixed')\n",
    "print('All snowlines loaded from file.')\n",
    "# snowlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f42c5-2e36-49a0-952b-b7f7aa86b7dc",
   "metadata": {},
   "source": [
    "## Filter snowlines to before September, merge snowlines and ERA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f48cc1-9a25-4f44-8d99-214b431bb3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add Month column to snowlines\n",
    "snowlines['Month'] = pd.DatetimeIndex(snowlines['datetime']).month.values\n",
    "eras['Month'] = pd.DatetimeIndex(eras['Date']).month.values\n",
    "# Remove observations after August\n",
    "snowlines = snowlines.loc[snowlines['Month'] <= 8]\n",
    "eras = eras.loc[eras['Month'] <= 8]\n",
    "# Unify date columns for merging\n",
    "snowlines['Date'] = snowlines['datetime'].values.astype('datetime64[D]')\n",
    "eras['Date'] = eras['Date'].values.astype('datetime64[D]')\n",
    "# Merge on site name and dates\n",
    "merged = pd.merge(snowlines, eras, on=['site_name', 'Date'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a0096-dc11-433f-90da-7f0b74d6e217",
   "metadata": {},
   "source": [
    "## Add climate cluster column to merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26e164-5d57-45d5-9818-a69a614c7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[['cluster', 'clustName']] = '', ''\n",
    "for cluster in aois['cluster'].drop_duplicates().values:\n",
    "    aois_cluster = aois.loc[aois['cluster']==cluster]\n",
    "    site_names = aois_cluster['RGIId'].drop_duplicates().values\n",
    "    merged.loc[merged['site_name'].isin(site_names), 'cluster'] = cluster\n",
    "    merged.loc[merged['site_name'].isin(site_names), 'clustName'] = aois_cluster['clustName'].values[0]\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5652a-7b2b-43d2-b68d-df2e421d85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define non-parametric fit function\n",
    "def svr_fit(X, y):    \n",
    "    model = SVR().fit(X, y)\n",
    "    score = model.score(X, y)\n",
    "    return model, score\n",
    "\n",
    "# Define linear fit function\n",
    "def linear_fit(X, y):\n",
    "    model = LinearRegression().fit(X,y)\n",
    "    score = model.score(X, y)\n",
    "    return model, score\n",
    "\n",
    "# Define function for K-folds cross-validation model fitting\n",
    "def kfolds_linear_fit(X, y, n_folds=10):\n",
    "    # Define K-folds\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    # Initialize parameters\n",
    "    coefs_PDD, coefs_snowfall, scores = [], [], []\n",
    "    # Iterate over fold indices\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        # Split X and y into training and testing\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Fit model to testing\n",
    "        model, score = linear_fit(X_train, y_train)\n",
    "        coefs_PDD.append(model.coef_[0])\n",
    "        coefs_snowfall.append(model.coef_[1])\n",
    "        scores.append(score)\n",
    "    # Calculate stats, compile in dataframe\n",
    "    df = pd.DataFrame({'coef_PDD_mean': [np.nanmean(coefs_PDD)],\n",
    "                       'coef_PDD_std': [np.nanstd(coefs_PDD)],\n",
    "                       'coef_PDD_median': [np.nanmedian(coefs_PDD)],\n",
    "                       'coef_PDD_MAD': [MAD(coefs_PDD)],\n",
    "                       'coef_snowfall_mean': [np.nanmean(coefs_snowfall)],\n",
    "                       'coef_snowfall_std': [np.nanstd(coefs_snowfall)],\n",
    "                       'coef_snowfall_median': [np.nanmedian(coefs_snowfall)],\n",
    "                       'coef_snowfall_MAD': [MAD(coefs_snowfall)],\n",
    "                       'score_mean': [np.nanmean(scores)],\n",
    "                       'score_median': [np.nanmedian(scores)]\n",
    "                      })\n",
    "    return df\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b699b-6118-4fed-bc5c-061ad9205cf0",
   "metadata": {},
   "source": [
    "## Fit linear and non-parametric models to PDDs and Snowfall vs. AARs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0aafad-a4fd-460a-93c1-95a28f82eb8a",
   "metadata": {},
   "source": [
    "### For each site separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c1180-f410-479d-b03e-21c7612987b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Suppress warnings to prevent kernel crashing (future warning from pandas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize results dataframe\n",
    "fit_sites_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over site names\n",
    "for site_name in tqdm(merged['site_name'].drop_duplicates().values):\n",
    "    # Subset data\n",
    "    merged_site = merged.loc[merged['site_name']==site_name]\n",
    "    # Grab O1 and O2 regions\n",
    "    o1 = aois.loc[aois['RGIId']==site_name, 'O1Region'].values[0]\n",
    "    o2 = aois.loc[aois['RGIId']==site_name, 'O2Region'].values[0]\n",
    "    # Grab cluster and cluster name\n",
    "    cluster, cluster_name = merged_site['cluster'].values[0], merged_site['clustName'].values[0]\n",
    "    # Fit linear trendline to AAR and Cumulative PDDs\n",
    "    X = merged_site[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values.reshape(-1, 2)\n",
    "    y = merged_site['AAR'].values\n",
    "    if (np.ravel(X)=='').all():\n",
    "        coefs_df = np.nan\n",
    "        print('none')\n",
    "    else:\n",
    "        coefs_df = kfolds_linear_fit(X, y)\n",
    "    # Save in dataframe\n",
    "    for col, value in list(zip(['site_name', 'O1Region', 'O2Region', \n",
    "                                'cluster', 'clustName', 'N'], \n",
    "                               [site_name, o1, o2, cluster, cluster_name, len(y)])):\n",
    "        coefs_df[col] = [value]\n",
    "    # Concatenate to full dataframe\n",
    "    fit_sites_df = pd.concat([fit_sites_df, coefs_df])\n",
    "\n",
    "# Save to file\n",
    "fit_sites_fn = os.path.join(scm_path, 'results', 'aar_pdd_snowfall_linear_fit_sites.csv')\n",
    "fit_sites_df.to_csv(fit_sites_fn, index=False)\n",
    "print('Data table saved to file:', fit_sites_fn)\n",
    "fit_sites_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa5932-b985-4fa2-b163-445a16df64c1",
   "metadata": {},
   "source": [
    "## Median trends by subregion and cluster based on each site's SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f64fca-a223-4d31-b3aa-ead24a3cc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add subregion name to merged data\n",
    "for site_name in tqdm(merged['site_name'].drop_duplicates().values):\n",
    "    o1 = aois.loc[aois['RGIId']==site_name, 'O1Region'].values[0]\n",
    "    o2 = aois.loc[aois['RGIId']==site_name, 'O2Region'].values[0]\n",
    "    subregion_name, color = f.determine_subregion_name_color(o1, o2)\n",
    "    merged.loc[merged['site_name']==site_name, 'O1Region'] = o1\n",
    "    merged.loc[merged['site_name']==site_name, 'O2Region'] = o2\n",
    "    merged.loc[merged['site_name']==site_name, 'Subregion'] = subregion_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709615b-4aa5-4e95-ac07-205e09ad296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate clusters colormap\n",
    "cluster_cmap_dict = {'W. Aleutians': '#1f78b4', \n",
    "                     'Continental': '#e31a1c',\n",
    "                     'Transitional-Continental': '#fb9a99',\n",
    "                     'Transitional-Temperate': '#b2df8a',\n",
    "                     'Temperate': '#33a02c'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967437b9-4086-4d34-8855-efeb4027f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df\n",
    "svr_fit_sites_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over sites\n",
    "for site_name in tqdm(merged['site_name'].drop_duplicates().values):\n",
    "    # Subset merged data to site\n",
    "    merged_site = merged.loc[merged['site_name']==site_name]\n",
    "    # Split into X and y\n",
    "    X = merged_site[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values.reshape(-1, 2)\n",
    "    y = merged_site['AAR'].values\n",
    "    # Fit SVR model\n",
    "    model, score = svr_fit(X, y)\n",
    "    # Predict values\n",
    "    y_pred = model.predict(X)\n",
    "    # Save in dataframe\n",
    "    svr_fit_df = pd.DataFrame({'site_name': [site_name],\n",
    "                               'O1Region': [merged_site['O1Region'].values[0]],\n",
    "                               'O2Region': [merged_site['O2Region'].values[0]],\n",
    "                               'Subregion': [merged_site['Subregion'].values[0]],\n",
    "                               'cluster': [merged_site['cluster'].values[0]],\n",
    "                               'clustName': [merged_site['clustName'].values[0]],\n",
    "                               'PDD': [X[:,0]],\n",
    "                               'snowfall': [X[:,1]],\n",
    "                               'AAR_pred': [y_pred],\n",
    "                               'score': [score]})\n",
    "    # Concatenate to full dataframe\n",
    "    svr_fit_sites_df = pd.concat([svr_fit_sites_df, svr_fit_df])\n",
    "svr_fit_sites_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4ef81-041c-4e17-ba9b-eb3c339821ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_df = pd.DataFrame()\n",
    "fig, ax = plt.subplots(5, 2, figsize=(10,12))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Iterate over subregion\n",
    "for i, subregion_name in enumerate(merged['Subregion'].drop_duplicates().values):\n",
    "    merged_subregion = merged.loc[merged['Subregion']==subregion_name]\n",
    "    for cluster_name in merged_subregion['clustName'].drop_duplicates().values:\n",
    "        merged_subregion_cluster = merged_subregion.loc[merged_subregion['clustName']==cluster_name]\n",
    "        X = merged_subregion_cluster[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values.reshape(-1, 2)\n",
    "        y = merged_subregion_cluster['AAR'].values\n",
    "        model, score = svr_fit(X, y)\n",
    "        aar_pred = model.predict(X)\n",
    "        df = pd.DataFrame({'Subregion': [subregion_name],\n",
    "                           'clustName': [cluster_name],\n",
    "                           'PDD': [X[:,0]],\n",
    "                           'snowfall': [X[:,1]],\n",
    "                           'AAR_pred': [aar_pred],\n",
    "                           'score': [score],\n",
    "                           'N': [len(y)]\n",
    "                          })\n",
    "        compiled_df = pd.concat([compiled_df, df])\n",
    "        ax[i].plot(X[:,0], aar_pred, '.', markersize=2, label=cluster_name,\n",
    "                   color=cluster_cmap_dict[cluster_name])\n",
    "    ax[i].set_title(subregion_name)\n",
    "    ax[i].set_xlim(0, 1500)\n",
    "    ax[i].set_ylim(0, 1)\n",
    "\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncols=4, markerscale=5)\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "# fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9300b6f-8e36-4c37-be3f-0c93ce4420e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(compiled_df['score'], bins=10)\n",
    "plt.xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f69af-058c-47e9-9692-01160b06f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_subset = merged.loc[(merged['Subregion']=='St. Elias Mtns.') & (merged['clustName']=='Transitional-Continental')]\n",
    "# X = merged_subset[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values.reshape(-1, 2)\n",
    "# y = merged_subset['AAR'].values\n",
    "# model_linear, score_linear = kfolds_linear_fit(X, y)\n",
    "# y_pred_linear = model_linear.predict(X)\n",
    "# model_svr, score_svr = svr_fit(X, y)\n",
    "# y_pred_svr = model_svr.predict(X)\n",
    "plt.plot(merged_subset['Cumulative_Positive_Degree_Days'], merged_subset['AAR'], '.')\n",
    "# plt.plot(X[:,0], y_pred_linear, '.m')\n",
    "# plt.plot(X[:,0], y_pred_svr, '.c')\n",
    "plt.xlabel('$\\Sigma$PDDs')\n",
    "plt.ylabel('AAR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124cf71-978a-4aa1-ad2d-dbcf83b29d0c",
   "metadata": {},
   "source": [
    "### For each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacacc71-11df-44b0-9dfb-966d06e04a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Initialize dataframe for storing results\n",
    "# fit_clusters_df = pd.DataFrame()\n",
    "\n",
    "# # Iterate over subregions \n",
    "# for cluster in tqdm(merged['cluster'].drop_duplicates().values):\n",
    "#     # Subset merged data to subregion\n",
    "#     merged_cluster = merged.loc[merged['cluster']==cluster]\n",
    "#     # Grab cluster name \n",
    "#     cluster_name = merged_cluster['clustName'].values[0]\n",
    "#     # Fit linear and SVR models to data\n",
    "#     X = merged_cluster[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values\n",
    "#     y = merged_cluster['AAR'].values\n",
    "#     if (np.ravel(X)=='').all():\n",
    "#         model_linear, score_linear = np.nan, np.nan\n",
    "#         model_svr, score_svr = np.nan, np.nan\n",
    "#     else:\n",
    "#         model_linear, score_linear = linear_fit(X, y)\n",
    "#         model_svr, score_svr = svr_fit(X, y)\n",
    "#         # plot\n",
    "#         plt.figure(figsize=(8,4))\n",
    "#         plt.plot(X[:,0], y, '.')\n",
    "#         plt.plot(X[:,0], model_linear.predict(X), '.b', label='Linear')\n",
    "#         plt.plot(X[:,0], model_svr.predict(X), '.m', label='SVR')\n",
    "#         plt.legend(loc='upper right')\n",
    "#         plt.xlabel('$\\Sigma$PDDs')\n",
    "#         plt.ylabel('AAR')\n",
    "#         plt.ylim(0,1)\n",
    "#         plt.title(cluster_name \n",
    "#                   + '\\nLinear score = ' + str(np.round(score_linear, 4)) \n",
    "#                   + '\\nSVR score = ' + str(np.round(score_svr, 4)))\n",
    "#         plt.show()\n",
    "#     # Save in dataframe\n",
    "#     df = pd.DataFrame({'cluster': [cluster],\n",
    "#                        'clustName': [cluster_name],\n",
    "#                        'coef_PDD': [model_linear.coef_[0]],\n",
    "#                        'coef_snowfall': [model_linear.coef_[1]],\n",
    "#                        'intercept': [model_linear.intercept_],\n",
    "#                        'score': [score_linear],\n",
    "#                        'N': [len(y)]})\n",
    "#     # Concatenate to full dataframe\n",
    "#     fit_clusters_df = pd.concat([fit_clusters_df, df])\n",
    "\n",
    "# # Sort by cluster\n",
    "# fit_clusters_df.sort_values(by='cluster', inplace=True)\n",
    "    \n",
    "# # Save to file\n",
    "# fit_clusters_fn = os.path.join(scm_path, 'results', 'aar_pdd_snowfall_linear_fit_clusters.csv')\n",
    "# fit_clusters_df.to_csv(fit_clusters_fn, index=False)\n",
    "# print('Data table saved to file:', fit_clusters_fn)\n",
    "# fit_clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b28002-17ac-4df0-88e5-cab0c9ddbbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fit_sites_df['score'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4969c18-8088-4c22-8da8-ac078095a522",
   "metadata": {},
   "source": [
    "## Fit a linear trend to max. PDDs and max. Snowfall vs. min. AARs for each subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05688685-1e8f-40cf-a9e4-d4cb680dd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings to prevent kernel crashing (future warning from pandas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize results dataframe\n",
    "fit_subregion_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over site names\n",
    "for o1, o2 in tqdm(aois[['O1Region', 'O2Region']].drop_duplicates().values):\n",
    "    # Grab subregion name\n",
    "    subregion_name, color = f.determine_subregion_name_color(o1, o2)\n",
    "    print(subregion_name)\n",
    "    # Grab site names\n",
    "    site_names = aois.loc[(aois['O1Region']==o1) & (aois['O2Region']==o2), 'RGIId'].values\n",
    "    # Subset data to subregion\n",
    "    merged_subregion = merged.loc[merged['site_name'].isin(site_names)]\n",
    "    # Fit linear trendline to AAR and Cumulative PDDs\n",
    "    X = merged_subregion[['Cumulative_Positive_Degree_Days', 'Cumulative_Snowfall_mwe']].values.reshape(-1, 2)\n",
    "    y = merged_subregion['AAR']\n",
    "    if (np.ravel(X)=='').all():\n",
    "        model_linear, score_linear = np.nan, np.nan\n",
    "        print('none')\n",
    "    else:\n",
    "        model_linear, score_linear = linear_fit(X, y)\n",
    "        # plot\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.plot(X[:,0], y, '.')\n",
    "        plt.plot(X[:,0], model_linear.predict(X), '.m', label='Linear')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlabel('$\\Sigma$PDDs')\n",
    "        plt.ylabel('AAR')\n",
    "        plt.ylim(0,1)\n",
    "        plt.title(subregion_name \n",
    "                  + '\\nLinear score = ' + str(np.round(score_linear, 4)))\n",
    "        plt.show()\n",
    "    # Save in dataframe\n",
    "    df = pd.DataFrame({'Subregion': [subregion_name],\n",
    "                       'O1Region': [o1],\n",
    "                       'O2Region': [o2],\n",
    "                       'coef_PDD': [model_linear.coef_[0]],\n",
    "                       'coef_snowfall': [model_linear.coef_[1]],\n",
    "                       'intercept': [model_linear.intercept_],\n",
    "                       'score': [score_linear],\n",
    "                       'N': [len(y)]})\n",
    "    # Concatenate to full dataframe\n",
    "    fit_subregion_df = pd.concat([fit_subregion_df, df])\n",
    "\n",
    "# Save to file\n",
    "fit_subregion_fn = os.path.join(scm_path, 'results', 'aar_pdd_snowfall_linear_fit_subregions.csv')\n",
    "fit_subregion_df.to_csv(fit_subregion_fn, index=False)\n",
    "print('Data table saved to file:', fit_subregion_fn)\n",
    "fit_subregion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c104c-521e-413f-bb32-1f0cd5233575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
