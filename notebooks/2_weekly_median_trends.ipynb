{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fee1d3-89a0-4332-91af-77fbee8cc9ed",
   "metadata": {},
   "source": [
    "# Calculate median weekly trends in snowlines for all sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ded5b9-6a41-4e78-aa7d-dbec024f6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "from scipy.stats import iqr\n",
    "from shapely import wkt\n",
    "import seaborn as sns\n",
    "import contextily as ctx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4325a8-0c88-45c3-b6a7-5fd875a8205f",
   "metadata": {},
   "source": [
    "## Define paths in directory, import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89c723-245e-4769-8633-a503980f94e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping-application/'\n",
    "sys.path.append(os.path.join(base_path, 'functions'))\n",
    "import model_analyze_utils as f\n",
    "\n",
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "figures_out_path = os.path.join(base_path, 'figures')\n",
    "study_sites_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/study-sites/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d398a-23a0-4431-aee8-5fe622f39b68",
   "metadata": {},
   "source": [
    "## Load compiled glacier boundaries (AOIs) and snowlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb97356-a7e0-4c83-af84-ceee07b044fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Load AOIs\n",
    "aois_path = os.path.join(scm_path, 'all_AOIs')\n",
    "aois_fn = 'all_aois.shp'\n",
    "aois = gpd.read_file(os.path.join(aois_path, aois_fn))\n",
    "print('All glacier boundaries loaded from file.')\n",
    "\n",
    "# -----Load snowlines\n",
    "snowlines_path = os.path.join(scm_path, 'all_snowlines')\n",
    "snowlines_fn = 'all_snowlines.csv'\n",
    "snowlines = pd.read_csv(os.path.join(snowlines_path, snowlines_fn))\n",
    "print('All snowlines loaded from file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada9ced-080b-493c-bdaf-8ac48a51bfb1",
   "metadata": {},
   "source": [
    "## Calculate weekly median trends for each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23ff0d-5260-47ad-86d0-9a053e716cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowlines_medians_fn = os.path.join(scm_path, 'results', 'all_snowlines_weekly_median_trends.csv') \n",
    "if not os.path.exists(snowlines_medians_fn):\n",
    "    # add week-of-year (WOY column to snowlines\n",
    "    snowlines['datetime'] = pd.to_datetime(snowlines['datetime'], format='mixed')\n",
    "    snowlines['WOY'] = snowlines['datetime'].dt.isocalendar().week\n",
    "    # determine columns to calculate weekly stats\n",
    "    columns = ['AAR', 'snowline_elevs_median_m', 'SCA_m2', 'ELA_from_AAR_m']\n",
    "    snowlines_medians = pd.DataFrame()\n",
    "    for site_name in tqdm(snowlines['site_name'].drop_duplicates().values):\n",
    "        # subset snowlines to site\n",
    "        snowlines_site = snowlines.loc[snowlines['site_name']==site_name]\n",
    "        # calculate weekly quartile trends\n",
    "        q1 = snowlines_site[['WOY'] + columns].groupby(by='WOY').quantile(0.25)\n",
    "        q1.columns = [x + '_P25' for x in q1.columns]\n",
    "        q2 = snowlines_site[['WOY'] + columns].groupby(by='WOY').quantile(0.5)\n",
    "        q2.columns = [x + '_P50' for x in q2.columns]\n",
    "        q3 = snowlines_site[['WOY'] + columns].groupby(by='WOY').quantile(0.75)\n",
    "        q3.columns = [x + '_P75' for x in q3.columns]\n",
    "        qs = pd.merge(q1, pd.merge(q2, q3, on='WOY'), on='WOY')\n",
    "        qs = qs.reindex(sorted(qs.columns), axis=1)\n",
    "        qs['WOY'] = qs.index\n",
    "        qs['site_name'] = site_name\n",
    "        # concatenate to medians dataframe\n",
    "        snowlines_medians = pd.concat([snowlines_medians, qs])\n",
    "    # save to file\n",
    "    snowlines_medians.to_csv(snowlines_medians_fn, index=False)\n",
    "    print('Median weekly snow trends saved to file: ', snowlines_medians_fn)\n",
    "        \n",
    "else:\n",
    "    snowlines_medians = pd.read_csv(snowlines_medians_fn)\n",
    "    print('Median weekly snow trends loaded from file.')\n",
    "    \n",
    "snowlines_medians\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec25ef-248b-4fff-8a5e-b7ac70f2827e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Compile RGI characteristics and minimum snow cover median statistics\n",
    "min_snow_cover_stats_fn = os.path.join(scm_path, 'results', 'min_snow_cover_stats.csv') \n",
    "# check if exists in directory\n",
    "if not os.path.exists(min_snow_cover_stats_fn):\n",
    "    # initialize dataframe for RGI stats and minimum snow cover statts\n",
    "    min_snow_cover_stats = pd.DataFrame()\n",
    "    \n",
    "    # iterate over site names in median snowlines dataframe\n",
    "    for site_name in tqdm(sorted(snowlines_medians['site_name'].drop_duplicates().values)):\n",
    "        # grab AOI for site\n",
    "        aoi_site = aois.loc[aois['RGIId']==site_name, :]\n",
    "        # grab median snowline stats for site\n",
    "        snowlines_medians_site = snowlines_medians.loc[snowlines_medians['site_name']==site_name, :]\n",
    "        # calculate min median stats\n",
    "        median_columns = [x for x in snowlines_medians.columns if 'P50' in x]\n",
    "        for column in median_columns:\n",
    "            if (column=='ELA_from_AAR_m_P50') or (column=='snowline_elevs_median_m_P50'):\n",
    "                aoi_site[column+'_max'] = snowlines_medians_site[column].max()\n",
    "            else:\n",
    "                aoi_site[column+'_min'] = snowlines_medians_site[column].min()\n",
    "        # concatenate to full dataframe\n",
    "        min_snow_cover_stats = pd.concat([min_snow_cover_stats, aoi_site])\n",
    "\n",
    "    # add subregion names and colors\n",
    "    min_snow_cover_stats[['Subregion', 'color']] = '', ''\n",
    "    min_snow_cover_stats[['O1Region', 'O2Region']] = min_snow_cover_stats[['O1Region', 'O2Region']].astype(int)\n",
    "    for o1, o2 in min_snow_cover_stats[['O1Region', 'O2Region']].drop_duplicates().values:\n",
    "        min_snow_cover_stats.loc[(min_snow_cover_stats['O1Region']==o1) \n",
    "                                 & (min_snow_cover_stats['O2Region']==o2), ['Subregion', 'color']] = f.determine_subregion_name_color(o1, o2)\n",
    "    # save to file\n",
    "    min_snow_cover_stats.to_csv(min_snow_cover_stats_fn, index=False)\n",
    "    print('Minimum median snow cover stats saved to file: ', min_snow_cover_stats_fn)\n",
    "        \n",
    "else:\n",
    "    # load from file\n",
    "    min_snow_cover_stats = pd.read_csv(min_snow_cover_stats_fn)\n",
    "    print('Minimum median snow cover stats loaded from file.')\n",
    "\n",
    "# reformat as GeoDataFrame\n",
    "min_snow_cover_stats['geometry'] = min_snow_cover_stats['geometry'].apply(wkt.loads)\n",
    "min_snow_cover_stats = gpd.GeoDataFrame(min_snow_cover_stats, crs='EPSG:4326')\n",
    "min_snow_cover_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2ecd1-99bf-4f9c-90d7-b8e5138c2aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
