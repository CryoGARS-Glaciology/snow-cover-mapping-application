{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mNQl_OJNtXf"
   },
   "source": [
    "# Load ERA5-Land air temperature and precipitation data, save as .csv at each study site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KGjaZBrNuJc"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "import rioxarray as rxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlEQRqPICO24"
   },
   "outputs": [],
   "source": [
    "# -----Define paths in directory\n",
    "\n",
    "# path to snow_cover_mapping_application/\n",
    "# base_path = 'drive/MyDrive/Research/CryoGARS-Glaciology/Advising/student-research/Alexandra-Friel/snow_cover_mapping_application/'\n",
    "\n",
    "# path to study-sites/\n",
    "study_sites_path = '/Users/raineyaberle/Google Drive/My Drive/Research/CryoGARS-Glaciology/Advising/student-research/Alexandra-Friel/snow_cover_mapping_application/study-sites/'\n",
    "\n",
    "# path to snow-cover-mapping/\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_0OdwBKEl-f"
   },
   "outputs": [],
   "source": [
    "# -----If using Google Colab, mount Google Drive so you can access your Drive folders\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-u8ICnmNx1q"
   },
   "outputs": [],
   "source": [
    "# -----Authenticate and intialize Google Earth Engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qX6j5TG0OtgV"
   },
   "outputs": [],
   "source": [
    "# Uncomment and use this to locate the folder above, if needed\n",
    "# os.listdir('drive/MyDrive/Research/PhD/snow_cover_mapping/snow_cover_mapping_application/study-sites/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZdAQZbMPEkl",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Grab list of site names with snowlines and no ERA data in folder\n",
    "os.chdir(study_sites_path)\n",
    "site_names = sorted([x[:-1] for x in glob.glob('*/', recursive = True)])\n",
    "site_names = [x for x in site_names if len(glob.glob(x + '/imagery/snowlines/*.csv')) > 0]\n",
    "# Only include those without ERA data already\n",
    "site_names = [x for x in site_names if len(glob.glob(x + '/ERA/*.csv'))==0]\n",
    "\n",
    "print('Number of sites to run = ' + str(len(site_names)))\n",
    "site_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load ERA5-Land elevations and reference to the geoid\n",
    "\n",
    "# Load ERA5-Land reference elevation data\n",
    "era_geo_fn = study_sites_path + '../snow-cover-mapping-application/inputs-outputs/geo_1279l4_0.1x0.1.grib2_v4_unpack.nc'\n",
    "era_geo = xr.open_dataset(era_geo_fn)\n",
    "era_geo = era_geo / 9.8\n",
    "# era_geo = xr.where(era_geo<=0, np.nan, era_geo / 9.8)\n",
    "# shift longitudes > 180 to longitude - 360\n",
    "era_geo.longitude.values[era_geo.longitude.values>180] = era_geo.longitude.values[era_geo.longitude.values>180] - 360\n",
    "\n",
    "# Load EGM96 geoid heights\n",
    "egm96_fn = os.path.join(base_path, 'inputs-outputs', 'us_nga_egm96_15.tif')\n",
    "egm96 = xr.open_dataset(egm96_fn)\n",
    "# interpolate to era_geo coordinates\n",
    "egm96_interp = egm96.interp(x=era_geo.longitude, y=era_geo.latitude, method='nearest')\n",
    "\n",
    "# Subtract the geoid from ERA5-Land ellipsoid heights\n",
    "era_elevs_geoid = era_geo.z.data - egm96_interp.band_data.data\n",
    "era_geo['z'] = (('time', 'latitude', 'longitude'), era_elevs_geoid)\n",
    "era_geo = era_geo.rio.write_crs('EPSG:4326')\n",
    "\n",
    "# Plot elevation\n",
    "plt.figure(figsize=(24,8))\n",
    "plt.imshow(era_geo.z.data[0], extent=(0,360,-90,90), cmap='terrain')\n",
    "plt.colorbar(label='meters', shrink=0.5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Compare DEMs to ERA5-Land elevations for a few sites\n",
    "for site_name in site_names[0:5]:\n",
    "\n",
    "    print(site_name)\n",
    "\n",
    "    # -----Load AOI (glacier outline) and reformat\n",
    "    AOI_fn = glob.glob(site_name + '/AOIs/*_outline.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    # reproject to WGS84\n",
    "    AOI_WGS = AOI.to_crs('EPSG:4326')\n",
    "    \n",
    "    # -----Load DEM\n",
    "    DEM_fn = glob.glob(site_name + '/DEMs/*.tif')[0]\n",
    "    if 'NASADEM' in DEM_fn:\n",
    "        DEM_name = 'NASADEM'\n",
    "    elif 'ArcticDEM' in DEM_fn:\n",
    "        DEM_name = 'ArcticDEM'\n",
    "    else:\n",
    "        DEM_name = 'USGS DEM'\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    # reproject to WGS84\n",
    "    DEM = DEM.rio.reproject('EPSG:4326')\n",
    "    # remove no data values\n",
    "    DEM = xr.where((DEM > 1e38) or (DEM<=-9999), np.nan, DEM)\n",
    "    DEM = DEM.rio.write_crs('EPSG:4326')\n",
    "    # clip to AOI\n",
    "    DEM_clip = DEM.rio.clip(AOI_WGS.geometry)\n",
    "\n",
    "    \n",
    "    # -----Interpolate ERA geo data to DEM coordinates\n",
    "    era_geo_interp = era_geo.interp(longitude=DEM.x, latitude=DEM.y, method='linear')\n",
    "    # clip to AOI\n",
    "    era_geo_interp_clip = era_geo_interp.rio.clip(AOI_WGS.geometry)\n",
    "    \n",
    "    # -----Plot\n",
    "    elev_min = np.nanmin([np.nanmin(DEM_clip.band_data.data[0]), np.nanmin(era_geo_interp_clip.z.data[0])])\n",
    "    elev_max = np.nanmax([np.nanmax(DEM_clip.band_data.data[0]), np.nanmax(era_geo_interp_clip.z.data[0])])\n",
    "    fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    dem_im = ax[0].imshow(DEM_clip.band_data.data[0], cmap='terrain', clim=(elev_min, elev_max),\n",
    "                          extent=(np.min(DEM.x.data), np.max(DEM.x.data), np.min(DEM.y.data), np.max(DEM.y.data)))\n",
    "    fig.colorbar(dem_im, ax=ax[0], shrink=0.5)\n",
    "    ax[0].set_title(DEM_name)\n",
    "    era5_im = ax[1].imshow(era_geo_interp_clip.z.data[0], cmap='terrain', clim=(elev_min, elev_max),\n",
    "                           extent=(np.min(DEM.x.data), np.max(DEM.x.data), np.min(DEM.y.data), np.max(DEM.y.data)))\n",
    "    fig.colorbar(era5_im, ax=ax[1], shrink=0.5)\n",
    "    ax[1].set_title('ERA5-Land elevation')\n",
    "    diff_im = ax[2].imshow(DEM_clip.band_data.data[0] - era_geo_interp_clip.z.data[0], cmap='Reds', \n",
    "                           extent=(np.min(DEM.x.data), np.max(DEM.x.data), np.min(DEM.y.data), np.max(DEM.y.data)))\n",
    "    fig.colorbar(diff_im, ax=ax[2], shrink=0.5)\n",
    "    ax[2].set_title('Difference')    \n",
    "    plt.show()\n",
    "    \n",
    "    diff_mean = np.nanmean(np.ravel(DEM_clip.band_data.data[0]) - np.ravel(era_geo_interp_clip.z.data[0]))                                    \n",
    "    print('Mean difference = ' + str(np.round(diff_mean,2)) + ' m \\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to grab mean band values over a region of interest \n",
    "def calculate_mean(image):\n",
    "    \n",
    "    # Select specific bands\n",
    "    image = image.select(bands_of_interest)\n",
    "    \n",
    "    # Calculate mean for the selected bands in the ROI\n",
    "    mean_values = image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=region,\n",
    "        scale=1000  # Adjust the scale as needed\n",
    "    )\n",
    "    return image.set(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzh6GNZPOCxe"
   },
   "outputs": [],
   "source": [
    "# Define date range for ERA5 querying\n",
    "date_start = '2012-11-01'\n",
    "date_end = '2023-11-01'\n",
    "\n",
    "# define bands to extract from ERA5-Land\n",
    "bands_of_interest = ['temperature_2m', \n",
    "                     'total_precipitation_sum', \n",
    "                     'snowfall_sum', \n",
    "                     'snowmelt_sum'] \n",
    "\n",
    "# define lapse rate to apply to air temperatures\n",
    "lapse_rate = 6 # deg C / km\n",
    "\n",
    "# adjust plot parameters\n",
    "plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "\n",
    "# Iterate over study sites\n",
    "for site_name in tqdm(site_names):\n",
    "\n",
    "    print(site_name)\n",
    "    \n",
    "    # check if file already exists in directory\n",
    "    out_path = site_name + '/ERA/'\n",
    "    output_fn = out_path + site_name + '_ERA5-Land_' + date_start + '_' + date_end + '.csv'\n",
    "    if os.path.exists(output_fn):\n",
    "        print('ERA5-Land CSV for these dates already exists in file, continuing... \\n')\n",
    "        continue\n",
    "\n",
    "    # -----Load AOI (glacier outline) and reformat\n",
    "    AOI_fn = glob.glob(site_name + '/AOIs/*_outline.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    # reproject to WGS84\n",
    "    AOI_WGS = AOI.to_crs('EPSG:4326')\n",
    "    # Reformat AOI for GEE querying\n",
    "    region = ee.Geometry.Polygon([[[AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.miny[0]],\n",
    "                                  [AOI_WGS.geometry.bounds.maxx[0], AOI_WGS.geometry.bounds.miny[0]],\n",
    "                                  [AOI_WGS.geometry.bounds.maxx[0], AOI_WGS.geometry.bounds.maxy[0]],\n",
    "                                  [AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.maxy[0]],\n",
    "                                  [AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.miny[0]]\n",
    "                                  ]])\n",
    "    \n",
    "    # -----Load DEM\n",
    "    if not os.path.exists(os.path.join(site_name, 'DEMs')):\n",
    "        print('No DEM in file, skipping...')\n",
    "        continue\n",
    "    DEM_fns = glob.glob(os.path.join(site_name, 'DEMs', '*.tif'))\n",
    "    if len(DEM_fns) < 1:\n",
    "        print('No DEM in file, skipping...')\n",
    "        continue\n",
    "    if 'NASADEM' in DEM_fns[0]:\n",
    "        DEM_fn = DEM_fns[0]\n",
    "    elif 'ArcticDEM' in DEM_fns[0]:\n",
    "        DEM_fn = glob.glob(site_name + '/DEMs/*_geoid.tif')[0]\n",
    "    elif 'USGS' in DEM_fns[0]:\n",
    "        DEM_fn = glob.glob(site_name + '/DEMs/*USGS*_geoid.tif')[0]\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    # reproject to WGS84\n",
    "    DEM = DEM.rio.reproject('EPSG:4326')\n",
    "    # remove no data values\n",
    "    DEM = xr.where((DEM > 1e38) or (DEM<=-9999), np.nan, DEM)\n",
    "    DEM = DEM.rio.write_crs('EPSG:4326')\n",
    "    # clip to AOI\n",
    "    DEM_clip = DEM.rio.clip(AOI_WGS.geometry)\n",
    "    # calculate mean elevation\n",
    "    elev_mean_DEM = np.nanmean(np.ravel(DEM_clip.band_data.data[0]))\n",
    "    \n",
    "    # -----Grab ERA5-Land elevation at AOI\n",
    "    # interpolate to DEM coordinates\n",
    "    era_geo_interp = era_geo.interp(longitude=DEM.x, latitude=DEM.y, method='linear')\n",
    "    # clip to AOI\n",
    "    era_geo_interp_clip = era_geo_interp.rio.clip(AOI_WGS.geometry)\n",
    "    # calculate mean elevation\n",
    "    elev_mean_era = np.nanmean(np.ravel(era_geo_interp_clip.z.data[0]))\n",
    "\n",
    "    # -----Define the dataset\n",
    "    era5_land = (ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n",
    "                 .filter(ee.Filter.date(date_start, date_end))\n",
    "                 .filterBounds(region)\n",
    "                )\n",
    "    \n",
    "    # -----Apply the calculate_mean function to each image in the collection\n",
    "    era5_land_mean = era5_land.map(calculate_mean)\n",
    "\n",
    "    # -----Compile statistics into DataFrame\n",
    "    # ceate empty lists to store the data\n",
    "    dates = []\n",
    "    mean_values_list = {band: [] for band in bands_of_interest}\n",
    "    # iterate over the ImageCollection to collect data\n",
    "    for image in era5_land_mean.getInfo()['features']:\n",
    "        date = pd.to_datetime(image['properties']['system:time_start'], unit='ms')  # Convert to datetime\n",
    "        dates.append(date)\n",
    "\n",
    "        mean_values = image['properties']\n",
    "        for band in bands_of_interest:\n",
    "            mean_values_list[band].append(mean_values[band])\n",
    "    # create a Pandas DataFrame\n",
    "    data = {'Date': dates}\n",
    "    data.update(mean_values_list)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # -----Convert air temperatures to Celsius (from Kelvin)\n",
    "    df['Temperature_Celsius'] = df['temperature_2m'] - 273.15\n",
    "\n",
    "    # -----Adjust air temperatures using reference elevations and lapse rate\n",
    "    df['Temperature_Celsius_Adjusted'] = df['Temperature_Celsius'] - lapse_rate * (elev_mean_DEM - elev_mean_era)/1e3\n",
    "    \n",
    "    # -----Add cumulative positive degree days\n",
    "    # Calculate Positive Degree Days (PDDs)\n",
    "    df['Positive_Degree_Days'] = df['Temperature_Celsius_Adjusted'].apply(lambda x: max(0, x))\n",
    "    # Calculate cumulative sum and reset at the start of each calendar year\n",
    "    df['Cumulative_Positive_Degree_Days'] = df.groupby(df['Date'].dt.year, group_keys=True)['Positive_Degree_Days'].cumsum()\n",
    "    # Reset cumulative sum to zero at the start of each year\n",
    "    df['Cumulative_Positive_Degree_Days'] = df.groupby(df['Date'].dt.year, group_keys=False)['Cumulative_Positive_Degree_Days'].apply(lambda x: x - x.iloc[0])\n",
    "    \n",
    "    # -----Add cumulative annual precipitation, snowfall, and snowmelt\n",
    "    # precipitation and snowfall: calculate for the water year\n",
    "    df['Water_Year'] = df['Date'].apply(lambda x: x.year if x.month >= 10 else x.year - 1) # add a water year column\n",
    "    df['Cumulative_Precipitation_mwe'] = df.groupby('Water_Year')['snowfall_sum'].cumsum()    \n",
    "    df['Cumulative_Snowfall_mwe'] = df.groupby('Water_Year')['total_precipitation_sum'].cumsum()   \n",
    "    # snowmelt: calculate for the calendar year\n",
    "    df['Cumulative_Snowmelt_mwe'] = df.groupby(df['Date'].dt.year)['snowmelt_sum'].cumsum()\n",
    "    \n",
    "    # -----Prepare DataFrame for saving\n",
    "    # Rename columns\n",
    "    df = df.rename(columns = {'total_precipitation_sum' : 'Precipitation_Meters', \n",
    "                              'snowfall_sum' : 'Snowfall_mwe',\n",
    "                              'snowmelt_sum' : 'Snowmelt_mwe'})\n",
    "    # Reorder columns\n",
    "    df = df[['Date', \n",
    "             'Temperature_Celsius',\n",
    "             'Temperature_Celsius_Adjusted',\n",
    "             'Precipitation_Meters',\n",
    "             'Cumulative_Precipitation_mwe',\n",
    "             'Snowfall_mwe',\n",
    "             'Cumulative_Snowfall_mwe',\n",
    "             'Snowmelt_mwe',\n",
    "             'Cumulative_Snowmelt_mwe',\n",
    "             'Positive_Degree_Days', \n",
    "             'Cumulative_Positive_Degree_Days']]\n",
    "    # Create directory for outputs if it does not exist\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "        print('Made directory for outputs: '+out_path)\n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(output_fn, index=False)\n",
    "    print('ERA5-Land data variables saved to file: ' + output_fn)\n",
    "\n",
    "    # -----Plot data variables\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(16,10))\n",
    "    # daily air temp\n",
    "    ax[0].plot(df.Date.values.astype('datetime64[ns]'), df['Temperature_Celsius'].values, \n",
    "               '.k', markersize=3, label='Raw')\n",
    "    ax[0].plot(df.Date.values.astype('datetime64[ns]'), df['Temperature_Celsius_Adjusted'].values, \n",
    "               '.', color='Gray', markersize=3, label='Adjusted for elevation')\n",
    "    ax[0].set_ylabel('Mean daily 2m air temperature [$^o$C]')\n",
    "    ax[0].legend(loc='best')\n",
    "    ax[0].grid()\n",
    "    # Cumulative positive degree days\n",
    "    ax0 = ax[0].twinx()\n",
    "    ax0.plot(df.Date.values.astype('datetime64[ns]'), df.Cumulative_Positive_Degree_Days, '.m', label='Cumulative PDDs')\n",
    "    ax0.set_ylabel('$\\Sigma$ Positive Degree Days', color='m')\n",
    "    ax0.tick_params(axis='y', colors='m')\n",
    "    # precip\n",
    "    ax[1].plot(df.Date.values.astype('datetime64[ns]'), df.Cumulative_Precipitation_mwe, '.c', label='$\\Sigma$ Precipitation')\n",
    "    # snowfall and snowmelt\n",
    "    ax[1].plot(df.Date.values.astype('datetime64[ns]'), df.Cumulative_Snowfall_mwe, '.b', label='$\\Sigma$ Snowfall')\n",
    "    ax[1].plot(df.Date.values.astype('datetime64[ns]'), df.Cumulative_Snowmelt_mwe, '.', color='orange', label='$\\Sigma$ Snowmelt')\n",
    "    ax[1].grid(True)\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('Date')\n",
    "    ax[1].set_ylabel('m.w.e.')\n",
    "    plt.show()\n",
    "\n",
    "    # save figure\n",
    "    fig_fn = out_path + site_name + '_ERA5-Land_' + date_start + '_' + date_end + '.png'\n",
    "    fig.savefig(fig_fn, dpi=300)\n",
    "    print('figure saved to file: ' + fig_fn)\n",
    "    \n",
    "    print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPUSxvA9DdKOQi56SFRph5u",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
