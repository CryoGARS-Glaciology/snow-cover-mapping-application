{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57798819-82ed-477d-81ad-a1429bad6670",
   "metadata": {},
   "source": [
    "# Estimate ELAs and melt factors of snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d102a4-ef90-4891-aae6-eefcfb4f0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import median_abs_deviation as MAD\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf1041-b03b-41e1-a43e-850ccfaef58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to data\n",
    "scm_path = '/Volumes/LaCie/raineyaberle/Research/PhD/snow_cover_mapping/'\n",
    "# scm_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e7158-398e-4d53-aeb7-39190bdf2347",
   "metadata": {},
   "source": [
    "## Load glacier boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e24c99-f8a5-4e13-824f-6621f227b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load glacier boundaries\n",
    "aois_fn = os.path.join(scm_path, 'analysis', 'all_aois.shp')\n",
    "aois = gpd.read_file(aois_fn)\n",
    "aois[['O1Region', 'O2Region']] = aois[['O1Region', 'O2Region']].astype(int)\n",
    "print('All AOIs loaded from file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4393a-db98-4680-93db-8b62836c91ad",
   "metadata": {},
   "source": [
    "## Estimate and save ELAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf1202-8e05-4481-86c5-00722094ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Monthly mean snowline altitudes\n",
    "# Check if results already exist in file\n",
    "obs_slas_monthly_fn = os.path.join(scm_path, 'analysis', 'monthly_SLAs_observed.csv')\n",
    "if os.path.exists(obs_slas_monthly_fn):\n",
    "    obs_slas_monthly = pd.read_csv(obs_slas_monthly_fn)\n",
    "    obs_slas_monthly['Date'] = pd.to_datetime(obs_slas_monthly['Date'])\n",
    "    print('Remotely-sensed monthly SLAs loaded from file.')\n",
    "else:\n",
    "    obs_slas_monthly = pd.DataFrame()\n",
    "\n",
    "    for rgi_id in tqdm(aois['RGIId'].drop_duplicates().values):\n",
    "        # Load compiled snow cover stats\n",
    "        scs_fn = os.path.join(scm_path, 'study-sites', rgi_id, f'{rgi_id}_snow_cover_stats.csv')\n",
    "        scs = pd.read_csv(scs_fn)\n",
    "        scs['datetime'] = pd.to_datetime(scs['datetime'], format='mixed')\n",
    "        # Remove wonky ELA values\n",
    "        scs.loc[scs['ELA_from_AAR_m'] > 1e10, 'ELA_from_AAR_m'] = np.nan\n",
    "        # Add Year and Month columns\n",
    "        scs['Year'] = pd.DatetimeIndex(scs['datetime']).year\n",
    "        scs['Month'] = pd.DatetimeIndex(scs['datetime']).month\n",
    "\n",
    "        # Remove pre-2016 values\n",
    "        scs = scs.loc[scs['Year'] >= 2016]\n",
    "\n",
    "        # Calculate the mean monthly snowline altitudes at each site\n",
    "        site_slas_monthly = scs.groupby(by=['Year', 'Month'])['ELA_from_AAR_m'].mean().reset_index()\n",
    "\n",
    "        # Add mean monthly PDDs and snowfall to dataframe\n",
    "        era_fn = os.path.join(scm_path, 'study-sites', rgi_id, 'ERA', f'{rgi_id}_ERA5_daily_means.csv')\n",
    "        era = pd.read_csv(era_fn)\n",
    "        era['Date'] = pd.to_datetime(era['Date'])\n",
    "        era['Year'] = pd.DatetimeIndex(era['Date']).year\n",
    "        era['Month'] = pd.DatetimeIndex(era['Date']).month\n",
    "        era_monthly = era.groupby(by=['Year', 'Month'])[['positive_degree_days_annual_sum', \n",
    "                                                         'mean_snowfall_sum_annual_sum']].mean().reset_index()\n",
    "        site_slas_monthly = site_slas_monthly.merge(era_monthly, on=['Year', 'Month'])\n",
    "        # Add RGI ID and minmium ELA\n",
    "        site_slas_monthly['RGIId'] = rgi_id\n",
    "        \n",
    "        # Add to full dataframe\n",
    "        obs_slas_monthly = pd.concat([obs_slas_monthly, site_slas_monthly], axis=0)\n",
    "    \n",
    "    # Add Date column\n",
    "    obs_slas_monthly['Date'] = [np.datetime64(f'{year}-{month}-01') if month >=10 else \n",
    "                                np.datetime64(f'{year}-0{month}-01')\n",
    "                                for year, month in obs_slas_monthly[['Year', 'Month']].values]\n",
    "\n",
    "    # Reorder columns\n",
    "    obs_slas_monthly = obs_slas_monthly[['RGIId', 'Date', 'Year', 'Month', 'ELA_from_AAR_m', \n",
    "                                         'positive_degree_days_annual_sum', \n",
    "                                         'mean_snowfall_sum_annual_sum']]\n",
    "    \n",
    "    # Save to file\n",
    "    obs_slas_monthly.to_csv(obs_slas_monthly_fn, index=False)\n",
    "    print('Remotely-sensed monthly SLAs saved to file:', obs_slas_monthly_fn)\n",
    "\n",
    "obs_slas_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384c62c-06fd-48b7-b697-7ec020d190a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Annual ELAs\n",
    "# Check if ELAs already exist in file\n",
    "obs_elas_annual_fn = os.path.join(scm_path, 'analysis', 'annual_ELAs_observed.csv')\n",
    "if os.path.exists(obs_elas_annual_fn):\n",
    "    obs_elas_annual = pd.read_csv(obs_elas_annual_fn)\n",
    "    obs_elas_annual['Date'] = pd.to_datetime(obs_elas_annual['Date'])\n",
    "    print('Remotely-sensed ELAs loaded from file.')\n",
    "else:\n",
    "    # Identify indices of maximum annual ELA\n",
    "    Imax = obs_slas_monthly.groupby(by=['RGIId', 'Year'])['ELA_from_AAR_m'].idxmax().dropna().values.astype(int)\n",
    "    obs_elas_annual = obs_slas_monthly.loc[Imax, ['RGIId', 'Date', 'Year', 'ELA_from_AAR_m', \n",
    "                                                  'positive_degree_days_annual_sum', 'mean_snowfall_sum_annual_sum']]\n",
    "    # Save to file\n",
    "    obs_elas_annual.to_csv(obs_elas_annual_fn, index=False)\n",
    "    print('Remotely-sensed ELAs saved to file:', obs_elas_annual_fn)\n",
    "\n",
    "obs_elas_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e141e2f-0ec4-4474-b754-f15f1cee35aa",
   "metadata": {},
   "source": [
    "## Fit linear models to monthly snowline altitudes to estimate melt factors of snow, $f_{snow}$:\n",
    "\n",
    "$f_{snow} * \\Sigma PDDs + \\Sigma Snowfall = h_{sl}$\n",
    "\n",
    "...\n",
    "\n",
    "$f_{snow} * \\Sigma PDDs = h_{sl} - \\Sigma Snowfall$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7540a-0da3-49e3-9dab-3f8a4542e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_Xy(df, X_cols, y_cols, scaler_type=StandardScaler()):\n",
    "    df_scaled = df.copy()\n",
    "    scaler = scaler_type.fit(df_scaled[X_cols + y_cols])\n",
    "    df_scaled[X_cols + y_cols] = scaler.transform(df_scaled[X_cols + y_cols])\n",
    "    return df_scaled, scaler\n",
    "\n",
    "def linear_fit(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    coefs = np.ravel(model.coef_)\n",
    "    return coefs, score\n",
    "    \n",
    "# Define function for K-folds cross-validation model fitting\n",
    "def kfolds_linear_fit(X, y, n_folds=5):\n",
    "    # Define K-folds\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    # Initialize parameters\n",
    "    fsnows, scores = [], []\n",
    "    # Iterate over fold indices\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        # Split X and y into training and testing\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Fit model to testing\n",
    "        fsnow, score = linear_fit(X_train, X_test, y_train, y_test)\n",
    "        fsnows.append(fsnow[0])\n",
    "        scores.append(score)\n",
    "    # Calculate stats, compile in dataframe\n",
    "    df = pd.DataFrame({'fsnow_mean': [np.nanmean(fsnow)],\n",
    "                       'fsnow_std': [np.nanstd(fsnow)],\n",
    "                       'fsnow_median': [np.nanmedian(fsnow)],\n",
    "                       'fsnow_MAD': [MAD(fsnow)],\n",
    "                       'score_mean': [np.nanmean(scores)],\n",
    "                       'score_median': [np.nanmedian(scores)]\n",
    "                      })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bcf87-9a85-4f92-b7a0-6ea91be81afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fits_obs_monthly_df = pd.DataFrame()\n",
    "for rgi_id in tqdm(obs_slas_monthly['RGIId'].drop_duplicates().values):\n",
    "    # subset and merge data\n",
    "    site_df = obs_slas_monthly.loc[obs_slas_monthly['RGIId']==rgi_id]\n",
    "    site_df.dropna(inplace=True)\n",
    "    # only include dates before October\n",
    "    site_df = site_df.loc[site_df['Date'].dt.month < 10]\n",
    "    # remove dates where PDD==0\n",
    "    site_df = site_df.loc[site_df['positive_degree_days_annual_sum'] > 0]\n",
    "    if len(site_df) >= 2:\n",
    "        X = site_df['positive_degree_days_annual_sum'].values.reshape(-1,1)\n",
    "        y = (site_df['ELA_from_AAR_m'] - site_df['mean_snowfall_sum_annual_sum']).values\n",
    "        # fit linear trendlines using K-folds cross-validation\n",
    "        fit_df = kfolds_linear_fit(X, y)\n",
    "        fit_df['RGIId'] = rgi_id\n",
    "        # add RGI regions and climate cluster to df\n",
    "        for col in ['O1Region', 'O2Region', 'Subregion']:\n",
    "            fit_df[col] = [aois.loc[aois['RGIId']==rgi_id, col].values[0]]\n",
    "        # concatenate to full dataframe\n",
    "        fits_obs_monthly_df = pd.concat([fits_obs_monthly_df, fit_df])\n",
    "\n",
    "fits_obs_monthly_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to file\n",
    "fits_obs_monthly_fn = os.path.join(scm_path, 'analysis', 'linear_fit_observed_monthly_ela_pdd_snowfall.csv')\n",
    "fits_obs_monthly_df.to_csv(fits_obs_monthly_fn, index=False)\n",
    "print('Linear fits saved to file:', fits_obs_monthly_fn)\n",
    "fits_obs_monthly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c28fc-7002-4897-9f86-df9a4feb629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fits_obs_monthly_df['fsnow_median'], bins=50)\n",
    "print(\"Median f_snow = \", np.nanmedian(fits_obs_monthly_df['fsnow_median']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712d424-80e6-4664-ada0-c084203e8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats\n",
    "print('Overall f_snow stats:')\n",
    "print(f'\\tMedian = {np.nanmedian(fits_obs_monthly_df[\"fsnow_median\"])} \\tMAD = {MAD(fits_obs_monthly_df[\"fsnow_median\"], nan_policy=\"omit\")}')\n",
    "print(f'\\tMean = {np.nanmean(fits_obs_monthly_df[\"fsnow_median\"])} \\tstd. = {np.nanstd(fits_obs_monthly_df[\"fsnow_median\"])}\\n')\n",
    "\n",
    "print(fits_obs_monthly_df.groupby(by='Subregion')['fsnow_median'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afd063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glacier-snow-cover-mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
